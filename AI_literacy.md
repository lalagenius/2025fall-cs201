# äººå·¥æ™ºèƒ½æ¦‚è§ˆ

Updated 2303 GMT+8 Jul 27 2025

2025 summer, Complied by Hongfei Yan



https://github.com/GMyhf/2025fall-cs201/



äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ˜¯ç ”ç©¶å’Œå¼€å‘èƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„æŠ€æœ¯å’Œæ–¹æ³•çš„å­¦ç§‘ï¼ŒåŒ…æ‹¬è¯­éŸ³è¯†åˆ«ã€å›¾åƒç†è§£ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€æœºå™¨äººç­‰[1] [2]ã€‚æ—©åœ¨1950å¹´ï¼Œè‰¾ä¼¦Â·å›¾çµæå‡ºäº†æ£€éªŒæœºå™¨æ™ºèƒ½çš„â€œæ¨¡ä»¿æ¸¸æˆâ€ï¼ˆå³**å›¾çµæµ‹è¯•**ï¼‰ï¼Œæ£€éªŒæœºå™¨æ˜¯å¦èƒ½è®©äººåˆ†ä¸æ¸…å…¶ä¸äººç±»å¯¹è¯çš„åŒºåˆ«ã€‚1956å¹´è¾¾ç‰¹èŒ…æ–¯ä¼šè®®ï¼ˆ**Dartmouth AI Workshop**ï¼‰å¬å¼€ï¼Œè¢«è®¤ä¸ºæ˜¯äººå·¥æ™ºèƒ½é¢†åŸŸçš„åˆ›å§‹æ—¶åˆ»ï¼Œçº¦ç¿°Â·éº¦å¡é”¡ç­‰äººé¦–æ¬¡æ­£å¼æå‡ºâ€œäººå·¥æ™ºèƒ½â€è¿™ä¸€æœ¯è¯­[1]ã€‚æ­¤åï¼ŒAIå‘å±•ç»å†äº†å¤šæ¬¡é«˜æ½®ä¸ä½è°·ï¼Œåˆ°21ä¸–çºªä¾èµ–äºå¼ºå¤§çš„è®¡ç®—èµ„æºã€æµ·é‡æ•°æ®å’Œæ–°ç®—æ³•çš„**æ·±åº¦å­¦ä¹ **æŠ€æœ¯å®ç°çªç ´ï¼Œæ¨åŠ¨AIè¿›å…¥å¹¿æ³›åº”ç”¨é˜¶æ®µã€‚



# 1. AIä¸‰å¤§æµæ´¾

äººå·¥æ™ºèƒ½çš„å‘å±•æ€æƒ³åˆ†ä¸ºä¸‰ä¸ªä¸»è¦æµæ´¾ï¼š

- **ç¬¦å·ä¸»ä¹‰ï¼ˆSymbolic     AIï¼‰**ï¼šæ ¸å¿ƒè§‚ç‚¹æ˜¯é€šè¿‡ç¬¦å·è¡¨ç¤ºå’Œé€»è¾‘æ¨ç†æ¥å®ç°æ™ºèƒ½ã€‚å…¸å‹æ–¹æ³•åŒ…æ‹¬ä¸“å®¶ç³»ç»Ÿã€æœç´¢ç®—æ³•ã€é€»è¾‘æ¨ç†ï¼ˆå¦‚ä¸€é˜¶é€»è¾‘ï¼‰ã€è§„åˆ’ç³»ç»Ÿç­‰ã€‚ä»£è¡¨äººç‰©æœ‰è‰¾ä¼¦Â·çº½å„å°”ã€èµ«ä¼¯ç‰¹Â·è¥¿è’™ã€çº¦ç¿°Â·éº¦å¡é”¡ç­‰ã€‚ç¬¦å·ä¸»ä¹‰å¼ºè°ƒå¯è§£é‡Šæ€§å¼ºï¼Œé€‚ç”¨äºæœ‰æ˜ç¡®è§„åˆ™çš„ä»»åŠ¡ï¼ˆå¦‚æ•°å­¦æ¨ç†ã€æ£‹ç±»æ¸¸æˆï¼‰ã€‚å…¶ä»£è¡¨æˆæœåŒ…æ‹¬20ä¸–çºª80å¹´ä»£çš„ä¸“å®¶ç³»ç»Ÿï¼ˆå¦‚DECå…¬å¸çš„XCONç³»ç»Ÿï¼Œæ˜¾è‘—æé«˜äº†é…ç½®æ•ˆç‡ï¼‰ä»¥åŠIBMçš„æ£‹ç±»ç¨‹åº**æ·±è“ï¼ˆDeep Blueï¼‰**ï¼Œ1997å¹´å‡»è´¥å›½é™…è±¡æ£‹å† å†›å¡æ–¯å¸•ç½—å¤«ã€‚ä½†ç¬¦å·ä¸»ä¹‰çš„ç¼ºç‚¹æ˜¯å­¦ä¹ èƒ½åŠ›å¼±ï¼Œéš¾ä»¥å¤„ç†æ¨¡ç³Šä¿¡æ¯ï¼Œéœ€è¦å¤§é‡æ‰‹å·¥ç¼–ç è§„åˆ™ã€‚

- **è¿æ¥ä¸»ä¹‰ï¼ˆConnectionismï¼‰**ï¼šæ ¸å¿ƒè§‚ç‚¹æ˜¯é€šè¿‡æ¨¡æ‹Ÿäººè„‘ç¥ç»å…ƒç½‘ç»œç»“æ„æ¥å®ç°æ™ºèƒ½ï¼Œä¾èµ–æ•°æ®é©±åŠ¨å­¦ä¹ ã€‚ä¸»è¦æ–¹æ³•æ˜¯å„ç§äººå·¥ç¥ç»ç½‘ç»œï¼ˆANNï¼‰å’Œæ·±åº¦å­¦ä¹ ï¼ˆå¦‚å·ç§¯ç¥ç»ç½‘ç»œCNNã€å¾ªç¯ç¥ç»ç½‘ç»œRNNã€Transformerç­‰ï¼‰ã€‚ä»£è¡¨äººç‰©åŒ…æ‹¬Geoffrey Hintonã€Yann LeCunã€Ilya Sutskeverã€David Rumelhartç­‰ã€‚çº¦ç¿°Â·éœæ™®è²å°”å¾·ï¼ˆJohn Hopfieldï¼‰ä¸Geoffrey Hintonäº2024å¹´è·å¾—è¯ºè´å°”ç‰©ç†å­¦å¥–ï¼Œä»¥è¡¨å½°ä»–ä»¬åœ¨ç¥ç»ç½‘ç»œé¢†åŸŸçš„å¥ åŸºæ€§è´¡çŒ®ã€‚è¿æ¥ä¸»ä¹‰æµæ´¾å¼•é¢†äº†è¿‘å¹´æ¥AIçš„ä¸»è¦çªç ´ï¼ˆâ€œå¼ºæ•°æ®ã€å¼±è§„åˆ™â€ï¼‰ã€‚å…¶ä»£è¡¨æˆæœåŒ…æ‹¬æœ€æ—©çš„å•å±‚æ„ŸçŸ¥æœºï¼ˆPerceptronï¼Œ1958å¹´ï¼‰ä»¥åŠ1986å¹´Rumelhartç­‰äººæå‡ºçš„**è¯¯å·®åå‘ä¼ æ’­ç®—æ³•**ï¼ˆBackpropagationï¼‰ï¼Œä½¿å¤šå±‚ç¥ç»ç½‘ç»œå¾—ä»¥é«˜æ•ˆè®­ç»ƒã€‚ç°ä»£è¿æ¥ä¸»ä¹‰ç³»ç»Ÿåœ¨å›¾åƒè¯†åˆ«ã€è¯­éŸ³è¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸå‡å–å¾—äº†å·¨å¤§æˆåŠŸï¼Œä¾‹å¦‚Googleçš„AlphaGoå’Œå„ç§è§†è§‰æ¨¡å‹ã€OpenAIçš„GPTç³»åˆ—è¯­è¨€æ¨¡å‹ç­‰[3]ã€‚
- **è¡Œä¸ºä¸»ä¹‰ï¼ˆBehaviorismï¼‰**ï¼šåœ¨AIé¢†åŸŸå¸¸æŒ‡â€œæœºå™¨äººè¡ŒåŠ¨æ´¾â€æˆ–å¼ºåŒ–å­¦ä¹ æ€æƒ³ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯æ™ºèƒ½ä½“é€šè¿‡ä¸ç¯å¢ƒäº¤äº’å¹¶æ ¹æ®åé¦ˆï¼ˆå¥–æƒ©ï¼‰è‡ªä¸»å­¦ä¹ ï¼Œæ— éœ€äº‹å…ˆå‡è®¾å†…éƒ¨çŸ¥è¯†ç»“æ„ã€‚ä»£è¡¨äººç‰©æœ‰ç½—å¾·å°¼Â·å¸ƒé²å…‹æ–¯ï¼ˆRodney Brooksï¼‰ã€æå¼€å¤ç­‰ã€‚è¡Œä¸ºä¸»ä¹‰AIå¼ºè°ƒâ€œè¡ŒåŠ¨ä¼˜å…ˆâ€ï¼Œå¯¹ç°ä»£æœºå™¨äººå­¦å’Œå¼ºåŒ–å­¦ä¹ å½±å“æ·±è¿œã€‚å…¸å‹åº”ç”¨æ˜¯åŸºäºå¼ºåŒ–å­¦ä¹ çš„ç³»ç»Ÿï¼Œå¦‚**AlphaGo/AlphaZero**ï¼ˆé€šè¿‡è‡ªæˆ‘åšå¼ˆå­¦ä¹ å›´æ£‹ç­–ç•¥ï¼‰å’Œè‡ªåŠ¨é©¾é©¶ç­‰ã€‚è¡Œä¸ºä¸»ä¹‰æµæ´¾ä¸‹çš„æ™ºèƒ½ä½“å¯è§†ä¸ºé€šè¿‡è¯•é”™å’Œç¯å¢ƒåé¦ˆæ¥ä¼˜åŒ–å†³ç­–ã€‚



# 2. AIçš„â€œä¸‰è¦ç´ â€ï¼šç®—æ³•ã€ç®—åŠ›ã€æ•°æ®

äººå·¥æ™ºèƒ½çš„å‘å±•ä¾èµ–äºä¸‰å¤§è¦ç´ ï¼š**ç®—æ³•**ï¼ˆAlgorithmï¼‰ã€**ç®—åŠ›**ï¼ˆComputeï¼‰å’Œ**æ•°æ®**ï¼ˆDataï¼‰ã€‚

- **ç®—æ³•ï¼ˆçµé­‚ï¼‰**ï¼šä¸åŒä»»åŠ¡ç±»å‹å¯¹åº”ä¸åŒç®—æ³•èŒƒå¼ã€‚å¸¸è§åˆ†ç±»åŒ…æ‹¬ç›‘ç£å­¦ä¹ ï¼ˆä½¿ç”¨æ ‡æ³¨æ•°æ®è®­ç»ƒæ¨¡å‹è¿›è¡Œåˆ†ç±»æˆ–å›å½’ï¼‰ã€æ— ç›‘ç£å­¦ä¹ ï¼ˆä»æ— æ ‡ç­¾æ•°æ®ä¸­æŒ–æ˜ç»“æ„ï¼Œå¦‚èšç±»ï¼‰ã€å¼ºåŒ–å­¦ä¹ ï¼ˆä½¿ç”¨å¥–æƒ©æœºåˆ¶ä¼˜åŒ–ç­–ç•¥ï¼‰ã€‚ä¾‹å¦‚ï¼Œé€»è¾‘å›å½’ç”¨äºåˆ†ç±»ï¼ˆç›‘ç£å­¦ä¹ ï¼‰ï¼ŒKMeansç”¨äºèšç±»ï¼ˆæ— ç›‘ç£å­¦ä¹ ï¼‰ã€‚æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ çš„ç®—æ³•ä¸æ–­æ¼”è¿›ï¼Œå¼•å…¥äº†å¤šå±‚ç¥ç»ç½‘ç»œã€æ³¨æ„åŠ›æœºåˆ¶ç­‰åˆ›æ–°æ¶æ„ã€‚
- **ç®—åŠ›ï¼ˆå¼•æ“ï¼‰**ï¼šæ·±åº¦å­¦ä¹ æ¨¡å‹å¾€å¾€éœ€è¦å·¨å¤§çš„è®¡ç®—èµ„æºã€‚GPU/TPUç­‰é«˜æ€§èƒ½ç¡¬ä»¶ä½¿å¾—è®­ç»ƒå¤§è§„æ¨¡ç¥ç»ç½‘ç»œæˆä¸ºå¯èƒ½ã€‚ä»¥PyTorchä¸ºä¾‹ï¼Œæˆ‘ä»¬å¯ä»¥ç®€å•æ£€æµ‹å½“å‰ç¡¬ä»¶ç¯å¢ƒä¸­GPUæˆ–Apple MPSçš„å¯ç”¨æ€§ã€‚
- **æ•°æ®ï¼ˆç‡ƒæ–™ï¼‰**ï¼šè®­ç»ƒæ¨¡å‹éœ€è¦å¤§é‡é«˜è´¨é‡çš„æ•°æ®ã€‚ç›‘ç£å­¦ä¹ å°¤å…¶ä¾èµ–æ ‡æ³¨æ•°æ®ã€‚ä¾‹å¦‚ï¼Œæé£é£ç­‰äººåœ¨2006å¹´å‘èµ·çš„ImageNetè®¡åˆ’æ”¶é›†äº†æ•°åƒä¸‡å¼ å›¾åƒï¼Œå¹¶ä¾æ‰˜ä¼—åŒ…æ ‡æ³¨åˆ›é€ äº†åŒ…å«1400ä¸‡å¼ æ ‡æ³¨å›¾ç‰‡çš„å¤§å‹æ•°æ®é›†ï¼Œå¤§å¤§æ¨åŠ¨äº†è®¡ç®—æœºè§†è§‰ç®—æ³•çš„å‘å±•ã€‚ä¸æ­¤åŒæ—¶ï¼Œæ— æ ‡ç­¾æ•°æ®ä¹Ÿé€šè¿‡è‡ªåŠ¨è®°å½•ç­‰æ–¹å¼æä¾›äº†æµ·é‡ä¿¡æ¯ï¼Œå¯ç”¨äºæ— ç›‘ç£å­¦ä¹ ã€‚æ€»ä¹‹ï¼Œç®—æ³•ã€ç®—åŠ›ä¸æ•°æ®ä¸‰è€…å…±åŒæ„æˆAIç³»ç»Ÿçš„åŸºç¡€ã€‚



# 3. å‰æ²¿åº”ç”¨æ¡ˆä¾‹

- **æ™ºèƒ½åšå¼ˆï¼šAlphaGo/AlphaZero**ï¼šDeepMindçš„AlphaGoç»“åˆäº†æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ã€å¼ºåŒ–å­¦ä¹ å’Œè’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰ï¼Œæˆä¸ºé¦–ä¸ªæˆ˜èƒœå›´æ£‹äººç±»å† å†›çš„AIç³»ç»Ÿã€‚2016å¹´AlphaGoä»¥4:1å‡»è´¥æä¸–çŸ³ï¼Œ2017å¹´ä»¥3:0æˆ˜èƒœæŸ¯æ´ã€‚å…¶å¼ºåŒ–å­¦ä¹ ç‰ˆæœ¬AlphaGo Zeroæ— éœ€äººç±»æ£‹è°±ï¼Œä»éšæœºå¯¹å¼ˆä¸­è‡ªå­¦ï¼Œç»è¿‡æ•°å‘¨è®­ç»ƒä¾¿è¶…è¶Šäº†åŸç‰ˆAlphaGoã€‚è¿›ä¸€æ­¥çš„AlphaZeroç”šè‡³èƒ½ä»é›¶å¼€å§‹è‡ªå­¦å¤šç§æ£‹ç±»ï¼ˆå›´æ£‹ã€å›½é™…è±¡æ£‹ã€æ—¥æœ¬å°†æ£‹ç­‰ï¼‰ï¼Œå±•ç°å‡ºè¶…å¼ºçš„ç­–ç•¥å­¦ä¹ èƒ½åŠ›ã€‚å®ƒè¯æ˜äº†æ”¾å¼ƒäººç±»ç»éªŒã€æœ‰æ¡ä»¶çš„è‡ªæˆ‘å¯¹å¼ˆï¼ˆself-playï¼‰å­¦ä¹ åœ¨æŸäº›é¢†åŸŸèƒ½å¸¦æ¥æ›´ä¼˜è§£ã€‚
- **è‡ªç„¶è¯­è¨€å¤„ç†ï¼šTransformerä¸GPT**ï¼šTransformeræ¨¡å‹ç”±Googleç ”ç©¶è€…åœ¨2017å¹´æå‡ºï¼ˆè‘—åè®ºæ–‡*Attention Is All You Need*ï¼‰ï¼Œå…¶æ ¸å¿ƒæ˜¯**è‡ªæ³¨æ„åŠ›æœºåˆ¶**ï¼Œå…è®¸æ¨¡å‹å¹¶è¡Œå¤„ç†åºåˆ—å¹¶æ•æ‰è¿œè·ç¦»ä¾èµ–[4]ã€‚Transformeræ¶æ„å¹¿æ³›åº”ç”¨äºå¤§è§„æ¨¡è‡ªç„¶è¯­è¨€å¤„ç†å’Œå…¶å®ƒé¢†åŸŸï¼Œå‚¬ç”Ÿäº†ä¼—å¤šé¢„è®­ç»ƒæ¨¡å‹å¦‚GPTç³»åˆ—å’ŒBERT[4]ã€‚GPTï¼ˆGenerative Pre-trained Transformerï¼‰æ˜¯OpenAIæ¨å‡ºçš„ä¸€ç±»è¯­è¨€æ¨¡å‹ï¼Œé‡‡ç”¨å·¨å¤§çš„Transformerè§£ç å™¨ç»“æ„è¿›è¡Œæ— ç›‘ç£é¢„è®­ç»ƒåå†å¾®è°ƒã€‚GPT-3äº2020å¹´é—®ä¸–ï¼Œæ‹¥æœ‰çº¦1750äº¿å‚æ•°[2]ï¼Œèƒ½å¤Ÿç”Ÿæˆè¿è´¯æµç•…çš„æ–‡æœ¬ï¼Œæ”¯æŒé›¶æ ·æœ¬å­¦ä¹ ï¼ˆzero-shotï¼‰å’Œå°‘æ ·æœ¬å­¦ä¹ ï¼ˆfew-shotï¼‰ï¼Œåœ¨ç¿»è¯‘ã€å¯¹è¯ã€å†™ä½œç­‰ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ã€‚**GPT-4**ï¼ˆ2023å¹´å‘å¸ƒï¼‰åœ¨GPT-3.5åŸºç¡€ä¸Šè¿›ä¸€æ­¥æ‰©å±•è§„æ¨¡å’Œèƒ½åŠ›ï¼Œæ˜¯ä¸€ä¸ªæ”¯æŒæ–‡æœ¬å’Œå›¾åƒè¾“å…¥çš„**å¤šæ¨¡æ€å¤§æ¨¡å‹**[5] [3]ã€‚GPT-4åœ¨åŒ…æ‹¬æ¨¡æ‹Ÿå¾‹å¸ˆèµ„æ ¼è€ƒè¯•ï¼ˆbar examï¼‰åœ¨å†…çš„å¤šé¡¹ä¸“ä¸šæµ‹è¯•ä¸­è¡¨ç°å‡ºç±»äººæ°´å¹³ï¼ˆæˆç»©åœ¨å‰10%ï¼‰[3]ã€‚ä¸å‰ä»£æ¨¡å‹ç›¸æ¯”ï¼ŒGPT-4æ›´åŠ å¯é ã€å¯Œæœ‰åˆ›é€ åŠ›ï¼Œèƒ½å¤Ÿå¤„ç†æ›´å¤æ‚ã€æ›´é•¿çš„æŒ‡ä»¤[5]ã€‚GPTç³»åˆ—æ¨¡å‹è¢«å¹¿æ³›åº”ç”¨äºå¯¹è¯æœºå™¨äººã€å†…å®¹ç”Ÿæˆã€ç¼–ç¨‹è¾…åŠ©ã€æ•™è‚²è¾…å¯¼ç­‰åœºæ™¯ã€‚

**ç¤ºä¾‹ï¼šä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œé—®ç­”**ã€‚ä»¥Hugging Face Transformerä¸ºä¾‹ï¼Œä¸‹è¿°ä»£ç è½½å…¥æœ¬åœ°ä¸­æ–‡é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œé—®ç­”æ¨ç†ï¼š



> | æ¨¡å‹                                     | é€‚ç”¨è¯­è¨€ | ç”¨é€”     |
>| ---------------------------------------- | -------- | -------- |
> | `distilbert-base-cased-distilled-squad`  | è‹±æ–‡     | è‹±æ–‡é—®ç­” |
> | `uer/roberta-base-chinese-extractive-qa` | ä¸­æ–‡     | ä¸­æ–‡é—®ç­” |
> 
> Q: å¦‚ä½•ç”¨**æµè§ˆå™¨æ‰‹åŠ¨ä¸‹è½½** `uer/roberta-base-chinese-extractive-qa` æ¨¡å‹ï¼Œåšåˆ°å®Œå…¨ **ç¦»çº¿éƒ¨ç½²** çš„æ­¥éª¤ï¼š
>
> ğŸ”— 1. æ‰“å¼€æ¨¡å‹é¡µé¢
>
> æµè§ˆå™¨è®¿é—®ï¼šhttps://huggingface.co/uer/roberta-base-chinese-extractive-qa
>
> ------
>
> ğŸ“ 2. è¿›å…¥ â€œFiles and versionsâ€ é¡µé¢ï¼Œæ‰‹åŠ¨ä¸‹è½½ä»¥ä¸‹å‡ ä¸ªå…³é”®æ–‡ä»¶ï¼š
>
> | æ–‡ä»¶å                    | è¯´æ˜                           |
>| ------------------------- | ------------------------------ |
> | `config.json`             | æ¨¡å‹ç»“æ„é…ç½®                   |
> | `pytorch_model.bin`       | æ¨¡å‹æƒé‡ï¼ˆå¾ˆå¤§ï¼Œ400MB å·¦å³ï¼‰   |
> | `tokenizer_config.json`   | tokenizer é…ç½®                 |
> | `vocab.txt`               | ä¸­æ–‡è¯è¡¨ï¼ˆå¿…éœ€ï¼‰               |
> | `special_tokens_map.json` | ç‰¹æ®Šç¬¦å·å®šä¹‰ï¼ˆå¯é€‰ä½†æ¨èï¼‰     |
> | `tokenizer.json`          | tokenizer çš„äºŒè¿›åˆ¶å½¢å¼ï¼ˆå¯é€‰ï¼‰ |
> 
> ä½ å¯ä»¥åœ¨ç½‘é¡µä¸­ä¾æ¬¡ç‚¹å‡»è¿™äº›æ–‡ä»¶ï¼Œç„¶åç‚¹å‡»å³ä¸Šè§’ â€œDownloadâ€ã€‚
>
> ------
>
> ğŸ—‚ï¸ 3. ä¸‹è½½åï¼ŒæŠŠå®ƒä»¬æ”¾å…¥ä¸€ä¸ªæœ¬åœ°æ–‡ä»¶å¤¹ï¼Œä¾‹å¦‚ï¼š
>
> ```
>./models/roberta-chinese-qa/
> â”œâ”€â”€ config.json
> â”œâ”€â”€ pytorch_model.bin
> â”œâ”€â”€ tokenizer_config.json
> â”œâ”€â”€ vocab.txt
> â”œâ”€â”€ special_tokens_map.json
> â”œâ”€â”€ tokenizer.json
> ```



```python
from transformers import pipeline

qa = pipeline(
    "question-answering",
    #model="./models/distilbert-base-cased-distilled-squad",
    model="./models/roberta-chinese-qa",
    tokenizer="./models/roberta-chinese-qa",
    framework="pt"  # æ˜¾å¼è¦æ±‚ä½¿ç”¨ PyTorch
)

result = qa(
    question="è°æ˜¯äººå·¥æ™ºèƒ½ä¹‹çˆ¶ï¼Ÿ",
    context="è‰¾ä¼¦Â·å›¾çµæ˜¯äººå·¥æ™ºèƒ½ä¹‹çˆ¶ï¼Œè¢«èª‰ä¸ºè®¡ç®—æœºç§‘å­¦çš„å¥ åŸºäººã€‚"
)

print(result)       # çœ‹å®Œæ•´ç»“æœ
print(result["answer"])  # è¾“å‡ºåº”ä¸ºï¼šè‰¾ä¼¦Â·å›¾çµ
```

ä¸Šè¿°ä»£ç ä¸­ï¼Œæˆ‘ä»¬æŒ‡å®šäº†æœ¬åœ°ä¸‹è½½çš„ä¸­æ–‡é—®ç­”æ¨¡å‹ç›®å½•ï¼Œé€šè¿‡pipelineæ¥å£ç›´æ¥è¿›è¡ŒæŠ½å–å¼é—®ç­”æ¨ç†ã€‚åœ¨çœŸå®åº”ç”¨ä¸­ï¼Œå¯æ›¿æ¢ä¸ºæ›´å¼ºå¤§çš„æ¨¡å‹ï¼ˆå¦‚GPT-4ï¼‰å¹¶ç»“åˆè¯­è¨€æç¤ºï¼ˆPromptï¼‰å®ç°æ›´å¤æ‚çš„è‡ªç„¶è¯­è¨€ä»»åŠ¡ã€‚



> ç”¨ä¸€ä¸ªæœ¬åœ°çš„ä¸­æ–‡é—®ç­”æ¨¡å‹ï¼Œåœ¨ä¸€æ®µæ–‡æœ¬é‡Œæå–é—®é¢˜çš„ç­”æ¡ˆã€‚
>
> âœ… 1. å¼•å…¥ Hugging Face çš„ `pipeline`
>
> ```python
>from transformers import pipeline
> ```
> 
> è¿™æ˜¯ Hugging Face `transformers` æä¾›çš„ç®€æ´ APIï¼Œç”¨äºå¿«é€Ÿæ„å»º NLP ä»»åŠ¡ç®¡é“ï¼Œä¾‹å¦‚æ–‡æœ¬åˆ†ç±»ã€é—®ç­”ã€ç¿»è¯‘ç­‰ã€‚
>
> 
>
> âœ… 2. æ„é€ é—®ç­”ä»»åŠ¡çš„ pipelineï¼ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼‰
>
> ```python
>qa = pipeline(
>  "question-answering",
>  #model="./distilbert-base-cased-distilled-squad",
>     model="./roberta-chinese-qa",      # ä½¿ç”¨æœ¬åœ°ä¸­æ–‡æ¨¡å‹ç›®å½•
>     framework="pt"                     # å¼ºåˆ¶ä½¿ç”¨ PyTorch
>    )
>    ```
> 
> å‚æ•°è¯´æ˜ï¼š
>
> | å‚æ•°                           | å«ä¹‰                                                         |
>| ------------------------------ | ------------------------------------------------------------ |
> | `"question-answering"`         | æŒ‡å®šä»»åŠ¡ç±»å‹æ˜¯æŠ½å–å¼é—®ç­”ï¼ˆextractive QAï¼‰                    |
> | `model="./roberta-chinese-qa"` | æŒ‡å‘æœ¬åœ°ä¸‹è½½çš„æ¨¡å‹æ–‡ä»¶å¤¹ï¼Œé‡Œé¢åŒ…å« `pytorch_model.bin`ã€`config.json` ç­‰ |
> | `framework="pt"`               | æ˜¾å¼è¦æ±‚ä½¿ç”¨ PyTorchï¼Œè€Œä¸æ˜¯ TensorFlowï¼Œé˜²æ­¢æ„å¤–åŠ è½½ TF æ¨¡å‹å¼•å‘é”™è¯¯ |
> 
> ğŸ“ `tokenizer` ä¼šè‡ªåŠ¨ä»æ¨¡å‹ç›®å½•ä¸­åŠ è½½ï¼Œæ— éœ€å•ç‹¬æŒ‡å®šã€‚
>
> ------
>
> âœ… 3. è¿è¡Œé—®ç­”æ¨ç†
>
> ```python
>result = qa(
>  question="è°æ˜¯äººå·¥æ™ºèƒ½ä¹‹çˆ¶ï¼Ÿ",
>  context="è‰¾ä¼¦Â·å›¾çµæ˜¯äººå·¥æ™ºèƒ½ä¹‹çˆ¶ï¼Œè¢«èª‰ä¸ºè®¡ç®—æœºç§‘å­¦çš„å¥ åŸºäººã€‚"
>    )
>    ```
> 
> è¯´æ˜ï¼š
>
> - è¾“å…¥çš„ `question` æ˜¯ç”¨æˆ·è¦é—®çš„é—®é¢˜ï¼›
>- `context` æ˜¯åŒ…å«ç­”æ¡ˆçš„ä¸Šä¸‹æ–‡æ–‡æœ¬ï¼ˆæ¨¡å‹ä¼šåœ¨é‡Œé¢æŸ¥æ‰¾ç­”æ¡ˆï¼‰ï¼›
> - è¿”å›çš„æ˜¯ä¸€ä¸ªåŒ…å« **é¢„æµ‹ç­”æ¡ˆä½ç½®ã€å†…å®¹ã€ç½®ä¿¡åº¦** çš„å­—å…¸ç»“æ„ã€‚
> 
> 
>
> ğŸ›  å¸¸è§è¡¥å……å»ºè®®ï¼š
>
> - **æ›´å¤æ‚ context**ï¼šä½ å¯ä»¥ç»™å®ƒæ›´å¤šæ®µè½ï¼Œå®ƒä¼šæ‰¾æœ€æœ‰å¯èƒ½çš„ç­”æ¡ˆï¼›
>
> - **ä¸­æ–‡ç²¾åº¦æé«˜**ï¼šä½ å¯ä»¥å°è¯• `hfl/chinese-roberta-wwm-ext-large` ä¹‹ç±»çš„æ¨¡å‹ï¼›
>
> 



# 4. æ·±åº¦å­¦ä¹ ä¸ç¥ç»ç½‘ç»œ

æ·±åº¦å­¦ä¹ æ˜¯è¿æ¥ä¸»ä¹‰æµæ´¾çš„é‡è¦ç»„æˆï¼Œä¸»è¦ä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œè‡ªåŠ¨å­¦ä¹ ç‰¹å¾å’Œæ¨¡å¼ã€‚æœ¬èŠ‚é‡ç‚¹ä»‹ç»ç¥ç»ç½‘ç»œçš„å…³é”®ç®—æ³•ä¸å®æˆ˜ç¤ºä¾‹ã€‚

## 4.1 åå‘ä¼ æ’­ç®—æ³•

åå‘ä¼ æ’­ï¼ˆBackpropagationï¼‰æ˜¯è®­ç»ƒç¥ç»ç½‘ç»œçš„æ ¸å¿ƒç®—æ³•ã€‚å…¶æ€æƒ³æ˜¯é€šè¿‡å‰å‘ä¼ æ’­è®¡ç®—è¾“å‡ºï¼Œç„¶ååå‘ä¼ æ’­è¯¯å·®å¹¶æ›´æ–°ç½‘ç»œæƒé‡ï¼Œä»¥æœ€å°åŒ–æŸå¤±å‡½æ•°[4]ã€‚å‰å‘ä¼ æ’­é˜¶æ®µï¼Œä»è¾“å…¥å±‚ç»è¿‡åŠ æƒæ±‚å’Œã€æ¿€æ´»å‡½æ•°ï¼ˆå¦‚ReLUã€Softmaxï¼‰é€å±‚è®¡ç®—è¾“å‡ºï¼›åå‘ä¼ æ’­é˜¶æ®µï¼Œåˆ©ç”¨é“¾å¼æ³•åˆ™è®¡ç®—æŸå¤±å¯¹æ¯ä¸ªå‚æ•°çš„æ¢¯åº¦ï¼Œç„¶åé‡‡ç”¨æ¢¯åº¦ä¸‹é™æˆ–è‡ªé€‚åº”ä¼˜åŒ–å™¨ï¼ˆå¦‚Adamï¼‰æ›´æ–°æƒé‡ã€‚åå‘ä¼ æ’­ä½¿å¾—å¤šå±‚æ·±åº¦ç½‘ç»œçš„è®­ç»ƒæˆä¸ºå¯èƒ½ï¼Œæ˜¯æ·±åº¦å­¦ä¹ å…´èµ·çš„åŸºçŸ³[3]ã€‚

**ç®—æ³•æµç¨‹æ¦‚è¿°**ï¼š 

1. **å‰å‘ä¼ æ’­**ï¼šå°†è¾“å…¥æ•°æ®é€å±‚ä¼ é€’ï¼Œè®¡ç®—æ¯å±‚ç¥ç»å…ƒè¾“å‡ºå¹¶æœ€ç»ˆå¾—åˆ°é¢„æµ‹ç»“æœã€‚ 
2. **è¯¯å·®è®¡ç®—**ï¼šä½¿ç”¨æŸå¤±å‡½æ•°ï¼ˆå¦‚äº¤å‰ç†µã€å‡æ–¹è¯¯å·®ï¼‰è®¡ç®—é¢„æµ‹è¾“å‡ºä¸çœŸå®æ ‡ç­¾ä¹‹é—´çš„è¯¯å·®ã€‚ 
3. **åå‘ä¼ æ’­**ï¼šä»è¾“å‡ºå±‚å‘è¾“å…¥å±‚åå‘ä¼ æ’­è¯¯å·®ï¼Œé€šè¿‡é“¾å¼æ³•åˆ™è®¡ç®—æ¯ä¸ªå‚æ•°çš„æ¢¯åº¦ã€‚ 
4. **å‚æ•°æ›´æ–°**ï¼šæ ¹æ®æ¢¯åº¦å¯¹æƒé‡å’Œåç½®è¿›è¡Œæ›´æ–°ï¼ˆå¦‚$w \leftarrow w - \eta \frac{\partial L}{\partial w}$ï¼‰ï¼Œå¸¸ç”¨ä¼˜åŒ–ç®—æ³•æœ‰éšæœºæ¢¯åº¦ä¸‹é™ã€Adamç­‰ã€‚ 
5. **é‡å¤è¿­ä»£**ï¼šå¯¹æ‰€æœ‰è®­ç»ƒæ ·æœ¬å¤šæ¬¡è¿­ä»£ï¼ˆå¤šä¸ªepochï¼‰ï¼Œç›´åˆ°æŸå¤±æ”¶æ•›æˆ–è¾¾åˆ°è®­ç»ƒè½®æ¬¡ä¸Šé™ã€‚

åå‘ä¼ æ’­çš„å¼•å…¥æå¤§æé«˜äº†ç½‘ç»œè®­ç»ƒæ•ˆç‡ï¼Œä½¿å¾—å¤šå±‚æ·±åº¦ç½‘ç»œæˆä¸ºå¯è¡Œã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæ·±å±‚ç½‘ç»œå¯èƒ½é¢ä¸´**æ¢¯åº¦æ¶ˆå¤±**æˆ–**æ¢¯åº¦çˆ†ç‚¸**ç­‰é—®é¢˜ï¼ˆå°¤å…¶ä½¿ç”¨Sigmoid/Tanhæ¿€æ´»å‡½æ•°æ—¶ï¼‰ï¼Œç°ä»£å®è·µå¸¸ç”¨ReLUåŠæ‰¹å½’ä¸€åŒ–ç­‰æ–¹æ³•ç¼“è§£ã€‚



> é˜…è¯»ï¼šPyTorch æ•™ç¨‹ï¼Œhttps://www.runoob.com/pytorch/pytorch-tutorial.html
>
> ä½¿ç”¨PyTorchå®ç°5ä¸ªä»åŸºç¡€æ¨¡å‹åˆ°è¾ƒå¤æ‚æ¨¡å‹çš„è®­ç»ƒä¸åº”ç”¨ã€‚ç›¸å…³ä»£ç åŠè¯´æ˜æ–‡æ¡£å·²æ•´ç†äº Markdown æ–‡ä»¶ä¸­ï¼Œè¯¦è§é¡¹ç›®ä»“åº“ï¼šhttps://github.com/GMyhf/2025spring-cs201/tree/main/LLM
>
> 1. `0_xor_bp_neural_net_manual`ï¼šæ‰‹åŠ¨å®ç°åå‘ä¼ æ’­çš„ç®€å•ç¥ç»ç½‘ç»œï¼Œç”¨äºå¼‚æˆ–é—®é¢˜ã€‚
> 2. `1_iris_neural_network`ï¼šæ„å»ºå¹¶è®­ç»ƒç”¨äºé¸¢å°¾èŠ±åˆ†ç±»çš„æ•°æ®é©±åŠ¨ç¥ç»ç½‘ç»œã€‚
> 3. `2_mnist_resnet18`ï¼šä½¿ç”¨ ResNet18 æ¨¡å‹å¯¹ MNIST æ‰‹å†™æ•°å­—è¿›è¡Œåˆ†ç±»ã€‚
> 4. `3_cifar10_resnet18`ï¼šå°† ResNet18 åº”ç”¨äº CIFAR-10 å›¾åƒåˆ†ç±»ä»»åŠ¡ã€‚
> 5. `4_tiny_imagenet_resnet50`ï¼šåŸºäº ResNet50 æ¨¡å‹å¤„ç† Tiny ImageNet å›¾åƒåˆ†ç±»ä»»åŠ¡ã€‚

## 4.2 å®ä¾‹ï¼šå¼‚æˆ–é—®é¢˜ï¼ˆXORï¼‰

å¼‚æˆ–é—®é¢˜æ˜¯ç»å…¸çš„éçº¿æ€§å¯åˆ†é—®é¢˜ï¼Œç”¨æ¥æ¼”ç¤ºç¥ç»ç½‘ç»œçš„å­¦ä¹ èƒ½åŠ›ã€‚ä¸€ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œå¯æ‰‹åŠ¨å®ç°åå‘ä¼ æ’­æ¥è§£å†³å¼‚æˆ–ã€‚ä»¥ä¸‹å…ˆç»™å‡ºç®€æ´çš„ä¼ªä»£ç ï¼Œå†ç»™å‡ºå¯ä»¥è¿è¡Œçš„Pythonä»£ç ç¤ºä¾‹å±•ç¤ºäº†åå‘ä¼ æ’­æ›´æ–°æƒé‡çš„æ–¹å¼ï¼š

```python
# å‡è®¾ç½‘ç»œç»“æ„ï¼šè¾“å…¥å±‚2ä¸ªèŠ‚ç‚¹ï¼Œéšè—å±‚2ä¸ªèŠ‚ç‚¹ï¼Œè¾“å‡ºå±‚1ä¸ªèŠ‚ç‚¹
# åˆå§‹åŒ–æƒé‡
W1 = random([...])  # è¾“å…¥åˆ°éšè—å±‚
W2 = random([...])  # éšè—å±‚åˆ°è¾“å‡ºå±‚
learning_rate = 0.1

for epoch in range(epochs):
    # å‰å‘è®¡ç®—
    hidden = sigmoid(X @ W1)       # Xä¸ºè¾“å…¥[å››ç»„XORè¾“å…¥]
    output = sigmoid(hidden @ W2)  # é¢„æµ‹
    # è®¡ç®—è¯¯å·®
    error = (y - output)           # yä¸ºçœŸå®æ ‡ç­¾
    # åå‘ä¼ æ’­ï¼ˆé“¾å¼æ³•åˆ™ï¼‰
    dW2 = hidden.T @ (error * output * (1 - output))
    dW1 = X.T @ ((error * output * (1 - output)) @ W2.T * hidden * (1 - hidden))
    # æ›´æ–°æƒé‡
    W2 += learning_rate * dW2
    W1 += learning_rate * dW1

```



```python
# å¯¹äºXORé—®é¢˜ï¼ˆè¾“å…¥ä¸º[0,0], [0,1], [1,0], [1,1]ï¼‰ï¼ŒæœŸæœ›è¾“å‡ºä¸º[0,1,1,0]
# æ‰‹åŠ¨å®ç°åå‘ä¼ æ’­ï¼Œæ²¡æœ‰ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œè¿™æœ‰åŠ©äºç†è§£åº•å±‚åŸç†
# https://www.geeksforgeeks.org/backpropagation-in-neural-network/
import numpy as np


class NeuralNetwork:
    def __init__(self, input_size, hidden_size, output_size):
        self.input_size = input_size  # è¾“å…¥ç‰¹å¾ç»´åº¦
        self.hidden_size = hidden_size  # éšè—å±‚ç¥ç»å…ƒæ•°é‡
        self.output_size = output_size  # è¾“å‡ºå±‚ç¥ç»å…ƒæ•°é‡

        # è¾“å…¥å±‚åˆ°éšè—å±‚çš„æƒé‡ï¼Œå½¢çŠ¶ä¸º (è¾“å…¥ç»´åº¦, éšè—å±‚ç»´åº¦)
        self.weights_input_hidden = np.random.randn(self.input_size, self.hidden_size)
        # éšè—å±‚åˆ°è¾“å‡ºå±‚çš„æƒé‡ï¼Œå½¢çŠ¶ä¸º (éšè—å±‚ç»´åº¦, è¾“å‡ºå±‚ç»´åº¦)
        self.weights_hidden_output = np.random.randn(self.hidden_size, self.output_size)

        # éšè—å±‚çš„åç½®ï¼Œå½¢çŠ¶ä¸º (1, éšè—å±‚ç»´åº¦)
        self.bias_hidden = np.zeros((1, self.hidden_size))
        # è¾“å‡ºå±‚çš„åç½®ï¼Œå½¢çŠ¶ä¸º (1, è¾“å‡ºå±‚ç»´åº¦)
        self.bias_output = np.zeros((1, self.output_size))

    def sigmoid(self, x):  # æ¿€æ´»å‡½æ•°ï¼Œå°†è¾“å…¥å‹ç¼©åˆ°(0,1)åŒºé—´
        return 1 / (1 + np.exp(-x))

    def sigmoid_derivative(self, x):
        return x * (1 - x)  # Sigmoidçš„å¯¼æ•°ï¼Œç”¨äºåå‘ä¼ æ’­ä¸­çš„æ¢¯åº¦è®¡ç®—

    def feedforward(self, X):
        # éšè—å±‚è®¡ç®—
        self.hidden_activation = np.dot(X, self.weights_input_hidden) + self.bias_hidden  # çº¿æ€§å˜æ¢
        self.hidden_output = self.sigmoid(self.hidden_activation)  # æ¿€æ´»å‡½æ•°

        # è¾“å‡ºå±‚è®¡ç®—
        self.output_activation = np.dot(self.hidden_output, self.weights_hidden_output) + self.bias_output
        self.predicted_output = self.sigmoid(self.output_activation)

        return self.predicted_output

    def backward(self, X, y, learning_rate):
        # è®¡ç®—è¾“å‡ºå±‚è¯¯å·®
        output_error = y - self.predicted_output  # è¯¯å·® = çœŸå®å€¼ - é¢„æµ‹å€¼
        # è®¡ç®—è¾“å‡ºå±‚çš„deltaï¼ˆæ¢¯åº¦çš„ä¸€éƒ¨åˆ†ï¼ŒæŸå¤±å¯¹æ¿€æ´»è¾“å…¥çš„æ¢¯åº¦ï¼‰
        output_delta = output_error * self.sigmoid_derivative(self.predicted_output)  # Delta = è¯¯å·® Ã— æ¿€æ´»å‡½æ•°å¯¼æ•°
        # output_delta = (y - Å·) * Ïƒ'(z_output)

        # è®¡ç®—éšè—å±‚è¯¯å·®ï¼ˆåå‘ä¼ æ’­ï¼‰
        hidden_error = np.dot(output_delta, self.weights_hidden_output.T)  # å°†è¯¯å·®ä»è¾“å‡ºå±‚åå‘ä¼ æ’­åˆ°éšè—å±‚
        # hidden_error = output_delta @ W_hidden_output^T
        # è®¡ç®—éšè—å±‚çš„deltaï¼ˆæŸå¤±å¯¹éšè—å±‚æ¿€æ´»è¾“å…¥çš„æ¢¯åº¦ï¼‰
        hidden_delta = hidden_error * self.sigmoid_derivative(self.hidden_output)  # Delta = è¯¯å·® Ã— æ¿€æ´»å‡½æ•°å¯¼æ•°
        # hidden_delta = (hidden_error) * Ïƒ'(z_hidden)

        # æ›´æ–°æƒé‡å’Œåç½®ï¼ˆä½¿ç”¨æ¢¯åº¦ä¸‹é™æ³•ï¼‰
        # è®¡ç®—å¹¶æ›´æ–°éšè—å±‚åˆ°è¾“å‡ºå±‚çš„æƒé‡
        self.weights_hidden_output += np.dot(self.hidden_output.T,
                                             output_delta) * learning_rate  # æƒé‡æ›´æ–°é‡ = å­¦ä¹ ç‡ Ã— (éšè—å±‚è¾“å‡ºè½¬ç½® Ã— è¾“å‡ºå±‚delta)
        # W_hidden_output += learning_rate * (hidden_output^T @ output_delta)

        # æ›´æ–°è¾“å‡ºå±‚åç½®ï¼ŒåŸºäºæ‰€æœ‰æ ·æœ¬çš„è¾“å‡ºå±‚deltaæ²¿åˆ—æ±‚å’Œ
        self.bias_output += np.sum(output_delta, axis=0, keepdims=True) * learning_rate  # åç½®æ›´æ–°é‡ = å­¦ä¹ ç‡ Ã— (æ²¿åˆ—æ±‚å’Œè¾“å‡ºå±‚delta)
        # b_output += learning_rate * sum(output_delta)

        # è®¡ç®—å¹¶æ›´æ–°ä»è¾“å…¥å±‚åˆ°éšè—å±‚çš„æƒé‡çš„æ¢¯åº¦
        self.weights_input_hidden += np.dot(X.T, hidden_delta) * learning_rate  # æƒé‡æ›´æ–°é‡ = å­¦ä¹ ç‡ Ã— (è¾“å…¥æ•°æ®è½¬ç½® Ã— éšè—å±‚delta)
        # W_input_hidden += learning_rate * (X^T @ hidden_delta)

        # æ›´æ–°éšè—å±‚åç½®ï¼ŒåŸºäºæ‰€æœ‰æ ·æœ¬çš„éšè—å±‚deltaæ²¿åˆ—æ±‚å’Œ
        # axis=0ï¼šæ²¿åˆ—æ±‚å’Œï¼Œèšåˆæ‰€æœ‰æ ·æœ¬çš„æ¢¯åº¦
        # keepdims=Trueï¼šä¿æŒåŸçŸ©é˜µçš„è¡Œæ•°ç»´åº¦ï¼Œç¡®ä¿åç½®æ›´æ–°çš„å½¢çŠ¶å…¼å®¹æ€§
        self.bias_hidden += np.sum(hidden_delta, axis=0, keepdims=True) * learning_rate  # åç½®æ›´æ–°é‡ = å­¦ä¹ ç‡ Ã— (æ²¿åˆ—æ±‚å’Œéšè—å±‚delta)
        # b_hidden += learning_rate * sum(hidden_delta)

    def train(self, X, y, epochs, learning_rate):
        for epoch in range(epochs):
            output = self.feedforward(X)  # å‰å‘ä¼ æ’­
            self.backward(X, y, learning_rate)  # åå‘ä¼ æ’­ä¸å‚æ•°æ›´æ–°
            if epoch % 4000 == 0:
                loss = np.mean(np.square(y - output))  # è®¡ç®—å‡æ–¹è¯¯å·®
                print(f"Epoch {epoch}, Loss:{loss}")


X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
y = np.array([[0], [1], [1], [0]])

# è¾“å…¥ç»´åº¦ 2ï¼ˆäºŒç»´äºŒè¿›åˆ¶ç‰¹å¾ï¼‰ï¼Œéšè—å±‚4ä¸ªç¥ç»å…ƒï¼Œè¾“å‡ºå±‚1ä¸ªç¥ç»å…ƒï¼ˆäºŒåˆ†ç±»é—®é¢˜ï¼‰
nn = NeuralNetwork(input_size=2, hidden_size=4, output_size=1)
# è®­ç»ƒæ€»è½®æ¬¡, å­¦ä¹ ç‡
nn.train(X, y, epochs=10000, learning_rate=0.1)

output = nn.feedforward(X)
print("Predictions after training:")
print(output)
"""
Epoch 0, Loss:0.2653166263520884
Epoch 4000, Loss:0.007000926683956338
Epoch 8000, Loss:0.001973630232951721
Predictions after training:
[[0.03613239]
 [0.96431351]
 [0.96058291]
 [0.03919372]]
"""
```

æœ€ç»ˆè®­ç»ƒåï¼Œè¯¥ç½‘ç»œå¯ä»¥å‡†ç¡®å­¦ä¹ XORé€»è¾‘ï¼ˆè®­ç»ƒæ•°æ®ï¼š${([0,0]\to0),([0,1]\to1),([1,0]\to1),([1,1]\to0)}$ï¼‰ï¼Œè¾“å‡ºæ¥è¿‘é¢„æœŸã€‚è¯¥ç¤ºä¾‹éªŒè¯äº†å¤šå±‚ç½‘ç»œå’Œåå‘ä¼ æ’­èƒ½è§£å†³çº¿æ€§æ¨¡å‹æ— æ³•å¤„ç†çš„é—®é¢˜ã€‚



## 4.3 å®ä¾‹ï¼šIrisæ•°æ®é›†åˆ†ç±»

**ä»»åŠ¡æè¿°**ï¼šä½¿ç”¨å…¨è¿æ¥ç¥ç»ç½‘ç»œå¯¹ç»å…¸çš„Irisï¼ˆé¸¢å°¾èŠ±ï¼‰æ•°æ®é›†è¿›è¡Œå¤šåˆ†ç±»ã€‚æ•°æ®é›†åŒ…å«150ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬4ä¸ªç‰¹å¾ï¼ˆèŠ±è¼å’ŒèŠ±ç“£é•¿åº¦/å®½åº¦ï¼‰ï¼Œåˆ†ä¸º3ä¸ªç±»åˆ«ã€‚

**å…³é”®æ­¥éª¤**ï¼šæ•°æ®é¢„å¤„ç†ï¼ˆæ ‡å‡†åŒ–ã€è®­ç»ƒ/æµ‹è¯•é›†åˆ’åˆ†ï¼‰ã€æ¨¡å‹æ„å»ºã€è®­ç»ƒä¸è¯„ä¼°ã€‚ç¤ºä¾‹ä»£ç ï¼ˆPyTorchï¼‰ï¼š

```python
import torch, torch.nn as nn, torch.optim as optim
from torch.utils.data import TensorDataset, DataLoader
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler


# å®šä¹‰æ¨¡å‹ç»“æ„
class IrisNet(nn.Module):
    def __init__(self, input_size=4, hidden_size=10, num_classes=3):
        super(IrisNet, self).__init__()
        self.net = nn.Sequential(
            nn.Linear(input_size, hidden_size),
            nn.ReLU(),
            nn.Linear(hidden_size, num_classes)
        )

    def forward(self, x):
        return self.net(x)


# è®­ç»ƒå‡½æ•°
def train(model, dataloader, criterion, optimizer, device):
    model.train()
    running_loss = 0.0
    for batch_X, batch_y in dataloader:
        batch_X, batch_y = batch_X.to(device), batch_y.to(device)

        optimizer.zero_grad()
        outputs = model(batch_X)
        loss = criterion(outputs, batch_y)
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * batch_X.size(0)

    return running_loss / len(dataloader.dataset)


# æµ‹è¯•å‡½æ•°
def evaluate(model, X, y, device):
    model.eval()
    with torch.no_grad():
        X, y = X.to(device), y.to(device)
        outputs = model(X)
        _, predicted = torch.max(outputs, 1)
        accuracy = (predicted == y).float().mean().item()
    return accuracy, predicted


# ä¸»ç¨‹åº
def main():
    # è®¾ç½®è®¾å¤‡
    if torch.backends.mps.is_available():
        device = torch.device("mps")
    elif torch.cuda.is_available():
        device = torch.device("cuda")
    else:
        device = torch.device("cpu")

    # åŠ è½½æ•°æ®
    iris = load_iris()
    X, y = iris.data, iris.target

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    """
    random_state=42
    è®¾å®šéšæœºæ•°ç§å­ï¼Œä»è€Œç¡®ä¿æ¯æ¬¡è¿è¡Œä»£ç æ—¶æ•°æ®åˆ’åˆ†çš„ç»“æœéƒ½æ˜¯ç›¸åŒçš„ã€‚è¿™æ ·åšå¯ä»¥ä½¿å®éªŒå…·æœ‰å¯é‡å¤æ€§ï¼Œ
    æœ‰åˆ©äºè°ƒè¯•å’Œç»“æœå¯¹æ¯”ã€‚

    stratify=y
    è¿™ä¸ªå‚æ•°è¡¨ç¤ºæŒ‰ç…§ y ä¸­çš„æ ‡ç­¾è¿›è¡Œåˆ†å±‚æŠ½æ ·ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œè®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸­å„ç±»åˆ«çš„
    æ¯”ä¾‹ä¼šä¸åŸå§‹æ•°æ®ä¸­çš„ç±»åˆ«æ¯”ä¾‹ä¿æŒä¸€è‡´ã€‚è¿™å¯¹äºç±»åˆ«ä¸å¹³è¡¡çš„æ•°æ®é›†å°¤ä¸ºé‡è¦ï¼Œå¯ä»¥
    é¿å…æŸä¸€ç±»åˆ«åœ¨åˆ’åˆ†æ—¶è¢«ä¸¥é‡ä½ä¼°æˆ–è¿‡é‡‡æ ·ã€‚
    """

    # æ ‡å‡†åŒ–ï¼šåªåœ¨è®­ç»ƒé›†ä¸Šè®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®ï¼Œå†å°†ç›¸åŒçš„å˜æ¢åº”ç”¨åˆ°æµ‹è¯•é›†ä¸Š
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

    # è½¬æ¢ä¸º Tensor
    X_train = torch.tensor(X_train, dtype=torch.float32)
    X_test = torch.tensor(X_test, dtype=torch.float32)
    y_train = torch.tensor(y_train, dtype=torch.long)
    y_test = torch.tensor(y_test, dtype=torch.long)

    # æ„é€  DataLoader
    train_dataset = TensorDataset(X_train, y_train)
    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)

    # æ¨¡å‹ã€æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨
    model = IrisNet().to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.01)

    # è®­ç»ƒ
    num_epochs = 100
    for epoch in range(1, num_epochs + 1):
        loss = train(model, train_loader, criterion, optimizer, device)
        if epoch % 10 == 0:
            print(f"Epoch [{epoch:3d}/{num_epochs}], Loss: {loss:.4f}")

    # è¯„ä¼°
    test_acc, test_pred = evaluate(model, X_test, y_test, device)
    print(f"\nâœ… Test Accuracy: {test_acc * 100:.2f}%")

    # ç¤ºä¾‹é¢„æµ‹
    sample = X_test[0].unsqueeze(0)
    sample_pred = model(sample.to(device))
    pred_class = torch.argmax(sample_pred, dim=1).item()
    print(f"ğŸ” Sample Prediction: True = {y_test[0].item()}, Predicted = {pred_class}")


if __name__ == "__main__":
    main()

```

> äº‘è™šæ‹Ÿæœºè¿è¡Œç»“æœï¼š
>
> <img src="https://raw.githubusercontent.com/GMyhf/img/main/img/image-20250223151816482.png" alt="image-20250223151816482" style="zoom:50%;" />



**ä»£ç è¯´æ˜ï¼š**

1. **æ•°æ®å‡†å¤‡**ï¼š
   - ä½¿ç”¨scikit-learnåŠ è½½é¸¢å°¾èŠ±æ•°æ®é›†
   - å°†æ•°æ®åˆ’åˆ†ä¸ºè®­ç»ƒé›†ï¼ˆ80%ï¼‰å’Œæµ‹è¯•é›†ï¼ˆ20%ï¼‰
   - ä½¿ç”¨æ ‡å‡†åŒ–å¤„ç†ï¼ˆStandardScalerï¼‰å¯¹ç‰¹å¾è¿›è¡Œå½’ä¸€åŒ–

2. **ç¥ç»ç½‘ç»œç»“æ„**ï¼š
   - è¾“å…¥å±‚ï¼š4ä¸ªç¥ç»å…ƒï¼ˆå¯¹åº”4ä¸ªç‰¹å¾ï¼‰
   - éšè—å±‚ï¼š10ä¸ªç¥ç»å…ƒï¼ˆä½¿ç”¨ReLUæ¿€æ´»å‡½æ•°ï¼‰
   - è¾“å‡ºå±‚ï¼š3ä¸ªç¥ç»å…ƒï¼ˆå¯¹åº”3ä¸ªç±»åˆ«ï¼‰

3. **è®­ç»ƒé…ç½®**ï¼š
   - ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼ˆCrossEntropyLossï¼‰
   - ä½¿ç”¨Adamä¼˜åŒ–å™¨ï¼ˆå­¦ä¹ ç‡0.01ï¼‰
   - è®­ç»ƒ100ä¸ªepoch

4. **è®­ç»ƒè¿‡ç¨‹**ï¼š
   - æ¯ä¸ªepochè®°å½•æŸå¤±å’Œå‡†ç¡®ç‡
   - æ¯10ä¸ªepochæ‰“å°è®­ç»ƒè¿›åº¦

5. **è¯„ä¼°ä¸é¢„æµ‹**ï¼š
   - æœ€ç»ˆåœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹å‡†ç¡®ç‡
   - åŒ…å«ä¸€ä¸ªé¢„æµ‹ç¤ºä¾‹å±•ç¤º

**è¾“å‡ºç¤ºä¾‹ï¼š**

```
$ python iris_neural_network.py 
Epoch [ 10/100], Loss: 0.2363
Epoch [ 20/100], Loss: 0.0899
Epoch [ 30/100], Loss: 0.0614
Epoch [ 40/100], Loss: 0.0634
Epoch [ 50/100], Loss: 0.0498
Epoch [ 60/100], Loss: 0.0492
Epoch [ 70/100], Loss: 0.0492
Epoch [ 80/100], Loss: 0.0451
Epoch [ 90/100], Loss: 0.0479
Epoch [100/100], Loss: 0.0436

âœ… Test Accuracy: 100.00%
ğŸ” Sample Prediction: True = 0, Predicted = 0
```

è¯¥ç½‘ç»œç»è¿‡è®­ç»ƒåï¼Œé€šå¸¸èƒ½åœ¨æµ‹è¯•é›†ä¸Šè¾¾åˆ°90%ä»¥ä¸Šçš„å‡†ç¡®ç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨å¤šå±‚å…¨è¿æ¥ç½‘ç»œå³å¯è¾ƒå¥½è§£å†³è¯¥å¤šåˆ†ç±»ä»»åŠ¡ï¼ˆIrisæ•°æ®é›†è§„æ¨¡å°ï¼Œç½‘ç»œä¸éœ€è¿‡æ·±ï¼‰ã€‚



**å¯è§†åŒ–ï¼šç›‘ç£å­¦ä¹  + æ— ç›‘ç£å­¦ä¹ ï¼ˆIris æ•°æ®é›†ï¼‰**

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.linear_model import LogisticRegression
from sklearn.cluster import KMeans
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score

# 1. åŠ è½½æ•°æ®
iris = load_iris()
X = iris.data
y = iris.target

# 2. æ ‡å‡†åŒ–æ•°æ®
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 3. åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼ˆç”¨äºç›‘ç£å­¦ä¹ ï¼‰
train_x, test_x, train_y, test_y = train_test_split(X_scaled, y, test_size=0.3, random_state=42)

# 4. ç›‘ç£å­¦ä¹ ï¼šé€»è¾‘å›å½’åˆ†ç±»
clf = LogisticRegression(max_iter=200)
clf.fit(train_x, train_y)
pred = clf.predict(test_x)
print("Logistic Regression Accuracy:", accuracy_score(test_y, pred))

# 5. æ— ç›‘ç£å­¦ä¹ ï¼šKMeans èšç±»ï¼ˆèšæˆ3ç±»ï¼‰
kmeans = KMeans(n_clusters=3, random_state=42)
clusters = kmeans.fit_predict(X_scaled)

# 6. å¯è§†åŒ–èšç±»ï¼ˆé™ç»´åˆ°äºŒç»´ï¼‰
from sklearn.decomposition import PCA
pca = PCA(n_components=2)
X_2d = pca.fit_transform(X_scaled)

plt.figure(figsize=(10, 5))

# èšç±»ç»“æœ
plt.subplot(1, 2, 1)
plt.scatter(X_2d[:, 0], X_2d[:, 1], c=clusters, cmap='viridis', s=50)
plt.title("KMeans Clustering (unsupervised)")

# åŸå§‹æ ‡ç­¾
plt.subplot(1, 2, 2)
plt.scatter(X_2d[:, 0], X_2d[:, 1], c=y, cmap='Set1', s=50)
plt.title("Ground Truth Labels (supervised)")

plt.show()

```

> ä½¿ç”¨ `LogisticRegression` è®­ç»ƒä¸€ä¸ªæœ‰ç›‘ç£åˆ†ç±»å™¨ï¼Œå¹¶è¾“å‡ºæµ‹è¯•é›†å‡†ç¡®ç‡ï¼›
>
> ä½¿ç”¨ `KMeans` è¿›è¡Œæ— ç›‘ç£èšç±»ï¼›
>
> ä½¿ç”¨ PCA å°† 4 ç»´æ•°æ®é™ç»´ä¸º 2 ç»´ï¼Œä»¥ä¾¿å¯è§†åŒ–èšç±»ç»“æœå’ŒçœŸå®æ ‡ç­¾ï¼›
>

å¦‚å›¾æ‰€ç¤ºï¼Œé€šè¿‡ä½¿ç”¨PCAå°†ç‰¹å¾é™è‡³äºŒç»´ï¼Œå¯è§†åŒ–èšç±»æ•ˆæœä¸çœŸå®åˆ†ç±»çš„å¯¹æ¯”ï¼š



<img src="https://raw.githubusercontent.com/GMyhf/img/main/img/image-20250727143806445.png" alt="image-20250727143806445" style="zoom: 67%;" />

<center>å›¾ï¼šIris æ•°æ®èšç±»ï¼ˆå·¦ï¼šç½‘ç»œèšç±»ç»“æœï¼›å³ï¼šçœŸå®ç±»åˆ«ï¼‰</center>



## 4.4 å®ä¾‹ï¼šMNISTæ‰‹å†™æ•°å­—è¯†åˆ«

MNISTæ˜¯æ‰‹å†™æ•°å­—åˆ†ç±»çš„åŸºå‡†æ•°æ®é›†ï¼ŒåŒ…å«60000å¼ 28Ã—28çš„è®­ç»ƒæ‰‹å†™æ•°å­—å›¾ç‰‡ï¼ˆ0â€“9å…±10ç±»ï¼‰ã€‚æˆ‘ä»¬ä½¿ç”¨ç»å…¸çš„CNNï¼ˆå¦‚ResNet18ï¼‰æ¥è¿›è¡Œåˆ†ç±»è®­ç»ƒã€‚

å…³é”®ç‚¹ï¼šåŠ è½½MNISTæ•°æ®é›†ï¼Œå®šä¹‰å·ç§¯ç¥ç»ç½‘ç»œï¼ˆä¾‹å¦‚é¢„è®­ç»ƒResNet18æˆ–è‡ªå®šä¹‰å°å‹CNNï¼‰ï¼Œè®­ç»ƒå¤šä¸ªepochåè¯„ä¼°ã€‚ä¸‹é¢æ˜¯ç¤ºä¾‹ä»£ç ï¼š

```python
import torch
import torchvision
import torchvision.transforms as transforms
import torch.nn as nn
import torch.optim as optim
import torchvision.models as models
import matplotlib.pyplot as plt
import numpy as np
import time

def main():
    # 1. æ•°æ®å¢å¼º + é¢„å¤„ç†
    transform_train = transforms.Compose([
        transforms.RandomRotation(10),  # éšæœºæ—‹è½¬
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,))  # MNIST æ˜¯å•é€šé“ï¼Œä½¿ç”¨ (0.5,) æ¥è§„èŒƒåŒ–
    ])

    transform_test = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,))
    ])

    # åŠ è½½ MNIST æ•°æ®é›†
    trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)

    testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform_test)
    testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2, pin_memory=True)

    classes = [str(i) for i in range(10)]  # MNIST ç±»åˆ«æ˜¯ 0 åˆ° 9

    # 2. è®¾ç½®è®¾å¤‡å’Œæ¨¡å‹
    device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
    print("Using device:", device)

    # åŠ è½½é¢„å®šä¹‰çš„ ResNet18 å¹¶ä¿®æ”¹è¾“å…¥å±‚å’Œè¾“å‡ºå±‚
    net = models.resnet18(weights=None)
    # ä¿®æ”¹è¾“å…¥å±‚çš„ç¬¬ä¸€ä¸ªå·ç§¯å±‚ï¼Œä½¿å…¶æ¥å—å•é€šé“ï¼ˆ1é€šé“ç°åº¦å›¾åƒï¼‰
    net.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    net.fc = nn.Linear(net.fc.in_features, 10)  # MNIST 10 ç±»
    net.to(device)

    # å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)

    # 3. è®­ç»ƒè¿‡ç¨‹
    best_loss = float('inf')
    patience = 10  # æé«˜è€å¿ƒ
    patience_counter = 0

    start_time = time.time()
    print("Starting training with early stopping...")
    for epoch in range(800):  # å¯é€‚å½“å¢å¤§ epoch
        net.train()
        epoch_loss = 0.0
        for i, data in enumerate(trainloader, 0):
            inputs, labels = data
            inputs, labels = inputs.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = net(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            epoch_loss += loss.item()
            if i % 100 == 99:
                print(f"[{epoch + 1}, {i + 1:5d}] loss: {loss.item():.3f}")

        avg_loss = epoch_loss / len(trainloader)
        print(f"[{epoch+1}] Avg Loss: {avg_loss:.3f}")

        if avg_loss < best_loss - 1e-4:
            best_loss = avg_loss
            patience_counter = 0
        else:
            patience_counter += 1
            print(f"No improvement. Patience: {patience_counter}/{patience}")
            if patience_counter >= patience:
                print("Early stopping triggered.")
                break

    end_time = time.time()
    execution_time_minutes = (end_time - start_time) / 60
    print(f"âœ… Training completed in {execution_time_minutes:.2f} minutes.")

    # ä¿å­˜æ¨¡å‹
    torch.save(net.state_dict(), './resnet18_mnist.pth')

    # 4. æµ‹è¯•å‡†ç¡®ç‡
    correct = 0
    total = 0
    net.eval()
    with torch.no_grad():
        for data in testloader:
            images, labels = data
            images, labels = images.to(device), labels.to(device)
            outputs = net(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    print(f"Accuracy on test images: {100 * correct / total:.2f}%")

    # æ¯ç±»å‡†ç¡®ç‡
    class_correct = list(0. for _ in range(10))
    class_total = list(0. for _ in range(10))
    with torch.no_grad():
        for data in testloader:
            images, labels = data
            images, labels = images.to(device), labels.to(device)
            outputs = net(images)
            _, predicted = torch.max(outputs.data, 1)
            c = (predicted == labels).squeeze()
            for i in range(len(labels)):
                class_correct[labels[i]] += c[i].item()
                class_total[labels[i]] += 1

    for i in range(10):
        print(f'Accuracy of {classes[i]:5s}: {100 * class_correct[i] / class_total[i]:.2f}%')

    # --- å¯è§†åŒ–é¢„æµ‹ ---

    def imshow_grid(images, labels, preds=None, classes=None, rows=8, cols=8):
        images = images.cpu() / 2 + 0.5  # unnormalize
        npimg = images.numpy()
        fig, axes = plt.subplots(rows, cols, figsize=(cols * 1.5, rows * 1.5))
        for i in range(rows * cols):
            r, c = divmod(i, cols)
            ax = axes[r, c]
            img = np.transpose(npimg[i], (1, 2, 0))
            ax.imshow(img.squeeze(), cmap="gray")
            title = f'{classes[labels[i]]}'
            if preds is not None:
                title += f'\nâ†’ {classes[preds[i]]}'
            ax.set_title(title, fontsize=8)
            ax.axis('off')
        plt.tight_layout()
        plt.show()

    # è·å–ä¸€æ‰¹å›¾åƒç”¨äºæ˜¾ç¤º
    dataiter = iter(testloader)
    images, labels = next(dataiter)
    while images.size(0) < 64:
        more_images, more_labels = next(dataiter)
        images = torch.cat([images, more_images], dim=0)
        labels = torch.cat([labels, more_labels], dim=0)
    images = images[:64]
    labels = labels[:64]

    # é¢„æµ‹
    net.eval()
    with torch.no_grad():
        outputs = net(images.to(device))
        _, predicted = torch.max(outputs, 1)

    # æ˜¾ç¤ºå›¾åƒç½‘æ ¼
    imshow_grid(images, labels, predicted.cpu(), classes=classes, rows=8, cols=8)

if __name__ == "__main__":
    import torch.multiprocessing
    torch.multiprocessing.set_start_method('spawn', force=True)
    main()


```

å…¸å‹ç»“æœï¼šä½¿ç”¨ResNet18èƒ½åœ¨MNISTä¸Šè¾¾åˆ°99%ä»¥ä¸Šçš„å‡†ç¡®ç‡ã€‚è¯¥ä»»åŠ¡å±•ç¤ºäº†æ·±åº¦å·ç§¯ç½‘ç»œåœ¨å›¾åƒåˆ†ç±»ä¸­çš„å¼ºå¤§èƒ½åŠ›ã€‚



> è¿è¡Œæœºå™¨
>
> <img src="https://raw.githubusercontent.com/GMyhf/img/main/img/202507261935350.png" alt="b452b39cfb47eb8bf5b640c828b6b71b" style="zoom:50%;" />
>
> 
>
> è¯¦ç»†è®­ç»ƒæ—¥å¿—
>
> ```
> /Users/hfyan/miniconda3/bin/python /Users/hfyan/git/2025spring-cs201/LLM/mnist_resnet18.py 
> 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.91M/9.91M [02:52<00:00, 57.6kB/s]
> 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28.9k/28.9k [00:00<00:00, 97.2kB/s]
> 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.65M/1.65M [00:04<00:00, 374kB/s]
> 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.54k/4.54k [00:00<00:00, 6.74kB/s]
> Using device: mps
> Starting training with early stopping...
> /Users/hfyan/miniconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.
>   warnings.warn(warn_msg)
> [1,   100] loss: 0.136
> [1,   200] loss: 0.132
> [1,   300] loss: 0.035
> [1,   400] loss: 0.098
> [1] Avg Loss: 0.150
> [2,   100] loss: 0.137
> [2,   200] loss: 0.030
> [2,   300] loss: 0.030
> [2,   400] loss: 0.015
> [2] Avg Loss: 0.052
> [3,   100] loss: 0.018
> [3,   200] loss: 0.105
> [3,   300] loss: 0.078
> [3,   400] loss: 0.026
> [3] Avg Loss: 0.039
> [4,   100] loss: 0.032
> [4,   200] loss: 0.056
> [4,   300] loss: 0.008
> [4,   400] loss: 0.013
> [4] Avg Loss: 0.031
> [5,   100] loss: 0.003
> [5,   200] loss: 0.025
> [5,   300] loss: 0.029
> [5,   400] loss: 0.022
> [5] Avg Loss: 0.027
> [6,   100] loss: 0.041
> [6,   200] loss: 0.022
> [6,   300] loss: 0.047
> [6,   400] loss: 0.005
> [6] Avg Loss: 0.023
> [7,   100] loss: 0.039
> [7,   200] loss: 0.000
> [7,   300] loss: 0.022
> [7,   400] loss: 0.014
> [7] Avg Loss: 0.018
> [8,   100] loss: 0.001
> [8,   200] loss: 0.044
> [8,   300] loss: 0.021
> [8,   400] loss: 0.002
> [8] Avg Loss: 0.019
> No improvement. Patience: 1/10
> [9,   100] loss: 0.002
> [9,   200] loss: 0.020
> [9,   300] loss: 0.002
> [9,   400] loss: 0.007
> [9] Avg Loss: 0.017
> [10,   100] loss: 0.027
> [10,   200] loss: 0.034
> [10,   300] loss: 0.031
> [10,   400] loss: 0.004
> [10] Avg Loss: 0.016
> [11,   100] loss: 0.003
> [11,   200] loss: 0.004
> [11,   300] loss: 0.005
> [11,   400] loss: 0.003
> [11] Avg Loss: 0.015
> [12,   100] loss: 0.011
> [12,   200] loss: 0.000
> [12,   300] loss: 0.031
> [12,   400] loss: 0.003
> [12] Avg Loss: 0.015
> No improvement. Patience: 1/10
> [13,   100] loss: 0.002
> [13,   200] loss: 0.002
> [13,   300] loss: 0.002
> [13,   400] loss: 0.019
> [13] Avg Loss: 0.013
> [14,   100] loss: 0.019
> [14,   200] loss: 0.004
> [14,   300] loss: 0.025
> [14,   400] loss: 0.003
> [14] Avg Loss: 0.013
> No improvement. Patience: 1/10
> [15,   100] loss: 0.003
> [15,   200] loss: 0.001
> [15,   300] loss: 0.011
> [15,   400] loss: 0.056
> [15] Avg Loss: 0.013
> [16,   100] loss: 0.034
> [16,   200] loss: 0.008
> [16,   300] loss: 0.001
> [16,   400] loss: 0.003
> [16] Avg Loss: 0.011
> [17,   100] loss: 0.008
> [17,   200] loss: 0.001
> [17,   300] loss: 0.001
> [17,   400] loss: 0.001
> [17] Avg Loss: 0.011
> [18,   100] loss: 0.009
> [18,   200] loss: 0.015
> [18,   300] loss: 0.002
> [18,   400] loss: 0.036
> [18] Avg Loss: 0.013
> No improvement. Patience: 1/10
> [19,   100] loss: 0.019
> [19,   200] loss: 0.001
> [19,   300] loss: 0.023
> [19,   400] loss: 0.005
> [19] Avg Loss: 0.011
> [20,   100] loss: 0.002
> [20,   200] loss: 0.007
> [20,   300] loss: 0.007
> [20,   400] loss: 0.005
> [20] Avg Loss: 0.011
> No improvement. Patience: 1/10
> [21,   100] loss: 0.001
> [21,   200] loss: 0.008
> [21,   300] loss: 0.012
> [21,   400] loss: 0.005
> [21] Avg Loss: 0.011
> [22,   100] loss: 0.007
> [22,   200] loss: 0.001
> [22,   300] loss: 0.001
> [22,   400] loss: 0.002
> [22] Avg Loss: 0.011
> No improvement. Patience: 1/10
> [23,   100] loss: 0.003
> [23,   200] loss: 0.002
> [23,   300] loss: 0.001
> [23,   400] loss: 0.014
> [23] Avg Loss: 0.011
> No improvement. Patience: 2/10
> [24,   100] loss: 0.003
> [24,   200] loss: 0.001
> [24,   300] loss: 0.003
> [24,   400] loss: 0.002
> [24] Avg Loss: 0.010
> [25,   100] loss: 0.016
> [25,   200] loss: 0.002
> [25,   300] loss: 0.010
> [25,   400] loss: 0.000
> [25] Avg Loss: 0.009
> [26,   100] loss: 0.001
> [26,   200] loss: 0.002
> [26,   300] loss: 0.006
> [26,   400] loss: 0.021
> [26] Avg Loss: 0.008
> [27,   100] loss: 0.002
> [27,   200] loss: 0.002
> [27,   300] loss: 0.017
> [27,   400] loss: 0.000
> [27] Avg Loss: 0.010
> No improvement. Patience: 1/10
> [28,   100] loss: 0.001
> [28,   200] loss: 0.012
> [28,   300] loss: 0.009
> [28,   400] loss: 0.000
> [28] Avg Loss: 0.008
> No improvement. Patience: 2/10
> [29,   100] loss: 0.001
> [29,   200] loss: 0.008
> [29,   300] loss: 0.009
> [29,   400] loss: 0.031
> [29] Avg Loss: 0.010
> No improvement. Patience: 3/10
> [30,   100] loss: 0.038
> [30,   200] loss: 0.001
> [30,   300] loss: 0.031
> [30,   400] loss: 0.001
> [30] Avg Loss: 0.011
> No improvement. Patience: 4/10
> [31,   100] loss: 0.017
> [31,   200] loss: 0.013
> [31,   300] loss: 0.029
> [31,   400] loss: 0.032
> [31] Avg Loss: 0.010
> No improvement. Patience: 5/10
> [32,   100] loss: 0.002
> [32,   200] loss: 0.000
> [32,   300] loss: 0.003
> [32,   400] loss: 0.001
> [32] Avg Loss: 0.009
> No improvement. Patience: 6/10
> [33,   100] loss: 0.009
> [33,   200] loss: 0.018
> [33,   300] loss: 0.001
> [33,   400] loss: 0.007
> [33] Avg Loss: 0.010
> No improvement. Patience: 7/10
> [34,   100] loss: 0.001
> [34,   200] loss: 0.001
> [34,   300] loss: 0.001
> [34,   400] loss: 0.011
> [34] Avg Loss: 0.010
> No improvement. Patience: 8/10
> [35,   100] loss: 0.004
> [35,   200] loss: 0.005
> [35,   300] loss: 0.009
> [35,   400] loss: 0.010
> [35] Avg Loss: 0.011
> No improvement. Patience: 9/10
> [36,   100] loss: 0.001
> [36,   200] loss: 0.004
> [36,   300] loss: 0.013
> [36,   400] loss: 0.007
> [36] Avg Loss: 0.008
> [37,   100] loss: 0.008
> [37,   200] loss: 0.003
> [37,   300] loss: 0.007
> [37,   400] loss: 0.002
> [37] Avg Loss: 0.010
> No improvement. Patience: 1/10
> [38,   100] loss: 0.002
> [38,   200] loss: 0.002
> [38,   300] loss: 0.011
> [38,   400] loss: 0.004
> [38] Avg Loss: 0.009
> No improvement. Patience: 2/10
> [39,   100] loss: 0.006
> [39,   200] loss: 0.003
> [39,   300] loss: 0.002
> [39,   400] loss: 0.001
> [39] Avg Loss: 0.008
> No improvement. Patience: 3/10
> [40,   100] loss: 0.000
> [40,   200] loss: 0.012
> [40,   300] loss: 0.011
> [40,   400] loss: 0.001
> [40] Avg Loss: 0.009
> No improvement. Patience: 4/10
> [41,   100] loss: 0.010
> [41,   200] loss: 0.008
> [41,   300] loss: 0.006
> [41,   400] loss: 0.002
> [41] Avg Loss: 0.008
> No improvement. Patience: 5/10
> [42,   100] loss: 0.005
> [42,   200] loss: 0.003
> [42,   300] loss: 0.014
> [42,   400] loss: 0.005
> [42] Avg Loss: 0.010
> No improvement. Patience: 6/10
> [43,   100] loss: 0.010
> [43,   200] loss: 0.000
> [43,   300] loss: 0.012
> [43,   400] loss: 0.002
> [43] Avg Loss: 0.008
> No improvement. Patience: 7/10
> [44,   100] loss: 0.001
> [44,   200] loss: 0.004
> [44,   300] loss: 0.035
> [44,   400] loss: 0.000
> [44] Avg Loss: 0.011
> No improvement. Patience: 8/10
> [45,   100] loss: 0.002
> [45,   200] loss: 0.014
> [45,   300] loss: 0.010
> [45,   400] loss: 0.014
> [45] Avg Loss: 0.010
> No improvement. Patience: 9/10
> [46,   100] loss: 0.001
> [46,   200] loss: 0.076
> [46,   300] loss: 0.001
> [46,   400] loss: 0.004
> [46] Avg Loss: 0.009
> No improvement. Patience: 10/10
> Early stopping triggered.
> âœ… Training completed in 27.72 minutes.
> Accuracy on test images: 99.57%
> Accuracy of 0    : 99.59%
> Accuracy of 1    : 99.91%
> Accuracy of 2    : 99.71%
> Accuracy of 3    : 99.80%
> Accuracy of 4    : 99.49%
> Accuracy of 5    : 99.33%
> Accuracy of 6    : 99.37%
> Accuracy of 7    : 99.22%
> Accuracy of 8    : 99.90%
> Accuracy of 9    : 99.31%
> 
> Process finished with exit code 0
> 
> ```
>
> 
>
> <img src="https://raw.githubusercontent.com/GMyhf/img/main/img/202507261936331.png" alt="22485e1e277b7dfea954fe0cd8a1af4f" style="zoom:50%;" />
>
> 



## 4.5 å®ä¾‹ï¼šCIFAR-10å›¾åƒåˆ†ç±»

CIFAR-10æ•°æ®é›†åŒ…å«60000å¼ 32Ã—32å½©è‰²å›¾åƒï¼Œå…±10ä¸ªç±»åˆ«ã€‚ç”±äºå›¾åƒæ›´å¤æ‚ï¼Œæˆ‘ä»¬ç»§ç»­ä½¿ç”¨æ›´å¼ºçš„æ¨¡å‹ï¼ˆå¦‚ResNet18æˆ–ResNet34ï¼‰è¿›è¡Œè®­ç»ƒã€‚æµç¨‹ç±»ä¼¼MNISTï¼Œä½†è¾“å…¥é€šé“ä¸º3ã€‚è®­ç»ƒåï¼Œç°ä»£æ¶æ„é€šå¸¸èƒ½è¾¾åˆ°70%â€“90%çš„æµ‹è¯•å‡†ç¡®ç‡ï¼ˆå–å†³äºç½‘ç»œæ·±åº¦å’Œè®­ç»ƒç­–ç•¥ï¼‰ã€‚è¯¥å®éªŒå¸®åŠ©å­¦ç”Ÿç†è§£å°å‹å½©è‰²å›¾åƒé›†ä¸Šçš„å·ç§¯ç½‘ç»œè®­ç»ƒè¦ç‚¹ï¼ˆå¦‚æ•°æ®å¢å¼ºã€å­¦ä¹ ç‡è°ƒæ•´ï¼‰ã€‚

```python
import torch
import torchvision
import torchvision.transforms as transforms
import torch.nn as nn
import torch.optim as optim
import torchvision.models as models
import matplotlib.pyplot as plt
import numpy as np
import time

def main():
    # 1. æ•°æ®å¢å¼º + é¢„å¤„ç†
    transform_train = transforms.Compose([
        transforms.RandomCrop(32, padding=4),
        transforms.RandomHorizontalFlip(),
        transforms.RandomRotation(10),  # éšæœºæ—‹è½¬
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),  # è‰²å½©è°ƒæ•´
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

    transform_test = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)

    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)
    testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2, pin_memory=True)

    classes = ('plane', 'car', 'bird', 'cat', 'deer',
               'dog', 'frog', 'horse', 'ship', 'truck')

    # 2. è®¾ç½®è®¾å¤‡å’Œæ¨¡å‹
    device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
    print("Using device:", device)

    # åŠ è½½é¢„å®šä¹‰çš„ ResNet18 å¹¶ä¿®æ”¹è¾“å‡ºå±‚
    net = models.resnet18(weights=None)
    net.fc = nn.Linear(net.fc.in_features, 10)  # CIFAR10 10 ç±»
    net.to(device)

    # å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)

    # 3. è®­ç»ƒè¿‡ç¨‹
    best_loss = float('inf')
    patience = 10 # æé«˜è€å¿ƒ
    patience_counter = 0

    start_time = time.time()
    print("Starting training with early stopping...")
    for epoch in range(800):  # å¯é€‚å½“å¢å¤§ epoch
        net.train()
        epoch_loss = 0.0
        for i, data in enumerate(trainloader, 0):
            inputs, labels = data
            inputs, labels = inputs.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = net(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            epoch_loss += loss.item()
            if i % 100 == 99:
                print(f"[{epoch + 1}, {i + 1:5d}] loss: {loss.item():.3f}")

        avg_loss = epoch_loss / len(trainloader)
        print(f"[{epoch+1}] Avg Loss: {avg_loss:.3f}")

        if avg_loss < best_loss - 1e-4:
            best_loss = avg_loss
            patience_counter = 0
        else:
            patience_counter += 1
            print(f"No improvement. Patience: {patience_counter}/{patience}")
            if patience_counter >= patience:
                print("Early stopping triggered.")
                break



    end_time = time.time()
    execution_time_minutes = (end_time - start_time) / 60
    print(f"âœ… Training completed in {execution_time_minutes:.2f} minutes.")


    # ä¿å­˜æ¨¡å‹
    torch.save(net.state_dict(), './resnet18_cifar10_data_augument.pth')

    # 4. æµ‹è¯•å‡†ç¡®ç‡
    correct = 0
    total = 0
    net.eval()
    with torch.no_grad():
        for data in testloader:
            images, labels = data
            images, labels = images.to(device), labels.to(device)
            outputs = net(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    print(f"Accuracy on test images: {100 * correct / total:.2f}%")

    # æ¯ç±»å‡†ç¡®ç‡
    class_correct = list(0. for _ in range(10))
    class_total = list(0. for _ in range(10))
    with torch.no_grad():
        for data in testloader:
            images, labels = data
            images, labels = images.to(device), labels.to(device)
            outputs = net(images)
            _, predicted = torch.max(outputs.data, 1)
            c = (predicted == labels).squeeze()
            for i in range(len(labels)):
                class_correct[labels[i]] += c[i].item()
                class_total[labels[i]] += 1

    for i in range(10):
        print(f'Accuracy of {classes[i]:5s}: {100 * class_correct[i] / class_total[i]:.2f}%')

    # --- å¯è§†åŒ–é¢„æµ‹ ---

    def imshow_grid(images, labels, preds=None, classes=None, rows=8, cols=8):
        images = images.cpu() / 2 + 0.5  # unnormalize
        npimg = images.numpy()
        fig, axes = plt.subplots(rows, cols, figsize=(cols * 1.5, rows * 1.5))
        for i in range(rows * cols):
            r, c = divmod(i, cols)
            ax = axes[r, c]
            img = np.transpose(npimg[i], (1, 2, 0))
            ax.imshow(img)
            title = f'{classes[labels[i]]}'
            if preds is not None:
                title += f'\nâ†’ {classes[preds[i]]}'
            ax.set_title(title, fontsize=8)
            ax.axis('off')
        plt.tight_layout()
        plt.show()

    # è·å–ä¸€æ‰¹å›¾åƒç”¨äºæ˜¾ç¤º
    dataiter = iter(testloader)
    images, labels = next(dataiter)
    while images.size(0) < 64:
        more_images, more_labels = next(dataiter)
        images = torch.cat([images, more_images], dim=0)
        labels = torch.cat([labels, more_labels], dim=0)
    images = images[:64]
    labels = labels[:64]

    # é¢„æµ‹
    net.eval()
    with torch.no_grad():
        outputs = net(images.to(device))
        _, predicted = torch.max(outputs, 1)

    # æ˜¾ç¤ºå›¾åƒç½‘æ ¼
    imshow_grid(images, labels, predicted.cpu(), classes=classes, rows=8, cols=8)

if __name__ == "__main__":
    import torch.multiprocessing
    torch.multiprocessing.set_start_method('spawn', force=True)
    main()

```



> è¯¦ç»†è®­ç»ƒæ—¥å¿—ï¼š
>
> ```
> /Users/hfyan/miniconda3/bin/python /Users/hfyan/Desktop/LLMs-from-scratch-main/runoob/pytorch-image-classification/image_classification-ResNet18-RandomCropFlipLR_Cosine.py 
> Using device: mps
> Starting training with early stopping...
> [1,   100] loss: 1.752
> [1,   200] loss: 1.675
> [1,   300] loss: 1.654
> [1] Avg Loss: 1.806
> [2,   100] loss: 1.497
> [2,   200] loss: 1.459
> [2,   300] loss: 1.453
> [2] Avg Loss: 1.520
> [3,   100] loss: 1.534
> [3,   200] loss: 1.383
> [3,   300] loss: 1.167
> [3] Avg Loss: 1.372
> [4,   100] loss: 1.390
> [4,   200] loss: 1.221
> [4,   300] loss: 1.238
> [4] Avg Loss: 1.244
> [5,   100] loss: 1.089
> [5,   200] loss: 1.020
> [5,   300] loss: 1.133
> [5] Avg Loss: 1.159
> ......
> No improvement. Patience: 1/10
> [192,   100] loss: 0.187
> [192,   200] loss: 0.293
> [192,   300] loss: 0.356
> [192] Avg Loss: 0.302
> [193,   100] loss: 0.223
> [193,   200] loss: 0.348
> [193,   300] loss: 0.309
> [193] Avg Loss: 0.301
> [194,   100] loss: 0.303
> [194,   200] loss: 0.219
> [194,   300] loss: 0.280
> [194] Avg Loss: 0.304
> No improvement. Patience: 1/10
> [195,   100] loss: 0.279
> [195,   200] loss: 0.296
> [195,   300] loss: 0.313
> [195] Avg Loss: 0.296
> [196,   100] loss: 0.254
> [196,   200] loss: 0.385
> [196,   300] loss: 0.280
> [196] Avg Loss: 0.300
> No improvement. Patience: 1/10
> [197,   100] loss: 0.216
> [197,   200] loss: 0.298
> [197,   300] loss: 0.290
> [197] Avg Loss: 0.298
> No improvement. Patience: 2/10
> [198,   100] loss: 0.267
> [198,   200] loss: 0.218
> [198,   300] loss: 0.367
> [198] Avg Loss: 0.290
> [199,   100] loss: 0.270
> [199,   200] loss: 0.240
> [199,   300] loss: 0.351
> [199] Avg Loss: 0.301
> No improvement. Patience: 1/10
> [200,   100] loss: 0.251
> [200,   200] loss: 0.227
> [200,   300] loss: 0.302
> [200] Avg Loss: 0.299
> No improvement. Patience: 2/10
> [201,   100] loss: 0.348
> [201,   200] loss: 0.301
> [201,   300] loss: 0.193
> [201] Avg Loss: 0.299
> No improvement. Patience: 3/10
> [202,   100] loss: 0.313
> [202,   200] loss: 0.329
> [202,   300] loss: 0.305
> [202] Avg Loss: 0.295
> No improvement. Patience: 4/10
> [203,   100] loss: 0.266
> [203,   200] loss: 0.254
> [203,   300] loss: 0.307
> [203] Avg Loss: 0.294
> No improvement. Patience: 5/10
> [204,   100] loss: 0.372
> [204,   200] loss: 0.295
> [204,   300] loss: 0.348
> [204] Avg Loss: 0.300
> No improvement. Patience: 6/10
> [205,   100] loss: 0.392
> [205,   200] loss: 0.353
> [205,   300] loss: 0.306
> [205] Avg Loss: 0.296
> No improvement. Patience: 7/10
> [206,   100] loss: 0.262
> [206,   200] loss: 0.213
> [206,   300] loss: 0.396
> [206] Avg Loss: 0.293
> No improvement. Patience: 8/10
> [207,   100] loss: 0.293
> [207,   200] loss: 0.204
> [207,   300] loss: 0.337
> [207] Avg Loss: 0.291
> No improvement. Patience: 9/10
> [208,   100] loss: 0.413
> [208,   200] loss: 0.294
> [208,   300] loss: 0.315
> [208] Avg Loss: 0.295
> No improvement. Patience: 10/10
> Early stopping triggered.
> âœ… Training completed in 79.91 minutes.
> Accuracy on test images: 83.57%
> Accuracy of plane: 83.70%
> Accuracy of car  : 92.20%
> Accuracy of bird : 78.70%
> Accuracy of cat  : 60.40%
> Accuracy of deer : 79.30%
> Accuracy of dog  : 77.40%
> Accuracy of frog : 90.30%
> Accuracy of horse: 92.50%
> Accuracy of ship : 88.50%
> Accuracy of truck: 92.70%
> 
> Process finished with exit code 0
> ```
>
> 
>
> <img src="https://raw.githubusercontent.com/GMyhf/img/main/img/202507280020181.jpg" alt="d561be986280572516ac1023e9ff715c" style="zoom:50%;" />
>
> 



## 4.6 å®ä¾‹ï¼šTiny ImageNet å›¾åƒåˆ†ç±»

Tiny ImageNetæ˜¯ä¸€ä¸ªæ›´å¤§è§„æ¨¡çš„å›¾åƒåˆ†ç±»ä»»åŠ¡ï¼ŒåŒ…å«200ä¸ªç±»åˆ«çš„64Ã—64å½©è‰²å›¾åƒï¼Œæ¯ç±»çº¦500å¼ è®­ç»ƒå›¾åƒã€‚æˆ‘ä»¬ä½¿ç”¨æ›´æ·±çš„ç½‘ç»œï¼ˆå¦‚ResNet50æˆ–æ›´å¤§æ¨¡å‹ï¼‰å’Œæ›´å……åˆ†çš„è®­ç»ƒè¿­ä»£æ¥è§£å†³ã€‚è¯¥ä»»åŠ¡éœ€è¦æ›´å¤šç®—åŠ›ï¼ˆGPUæ”¯æŒï¼‰å’ŒæŠ€æœ¯ï¼ˆæ¯”å¦‚å­¦ä¹ ç‡è°ƒåº¦ã€æ­£åˆ™åŒ–ï¼‰ã€‚å®Œæˆåå­¦ç”Ÿå°†æŒæ¡ä»ä»£ç å®ç°åˆ°å®æˆ˜è°ƒä¼˜çš„å®Œæ•´æµç¨‹ï¼Œä½“ä¼šè®­ç»ƒé«˜å¤æ‚åº¦æ¨¡å‹çš„å·¥ç¨‹æŒ‘æˆ˜ã€‚

### 1.å‡†å¤‡Tiny ImageNetæ•°æ®é›†

Tiny ImageNetã€‚å®ƒåŒ…å« 200 ä¸ªç±»åˆ«ï¼Œæ¯ä¸ªç±»åˆ« 500 å¼ è®­ç»ƒå›¾ç‰‡ï¼Œæ€»æ•°æ®é‡å¤§çº¦ 500MBï¼Œéå¸¸é€‚åˆå®éªŒå’Œè°ƒè¯•ã€‚

ä¸‹è½½ `wget http://cs231n.stanford.edu/tiny-imagenet-200.zip`ï¼Œè®°237MBã€‚

éªŒè¯é›†é€šå¸¸è§£å‹åæ‰€æœ‰å›¾ç‰‡ä¼šåœ¨åŒä¸€ä¸ªæ–‡ä»¶å¤¹ä¸­ï¼Œè€Œ ImageFolder è¦æ±‚æ¯ä¸ªç±»åˆ«æœ‰ç‹¬ç«‹å­æ–‡ä»¶å¤¹ã€‚ä½ éœ€è¦æ ¹æ®å®˜æ–¹æä¾›çš„ éªŒè¯é›†æ ‡ç­¾æ–‡ä»¶ï¼Œå¦‚ val_annotations.txtï¼Œå¯¹å›¾ç‰‡è¿›è¡Œåˆ†ç±»æ•´ç†ã€‚å¸¸è§çš„åšæ³•æ˜¯ç¼–å†™ä¸€ä¸ªè„šæœ¬ï¼Œæ ¹æ®æ–‡ä»¶ä¸­çš„ç±»åˆ«ä¿¡æ¯å°†å›¾ç‰‡ç§»åŠ¨åˆ°å¯¹åº”çš„å­æ–‡ä»¶å¤¹ä¸­ã€‚

è„šæœ¬`tinyimagenet.sh`

```sh
#!/bin/bash

# download and unzip dataset
#wget http://cs231n.stanford.edu/tiny-imagenet-200.zip
unzip tiny-imagenet-200.zip

current="$(pwd)/tiny-imagenet-200"

# training data
cd $current/train
for DIR in $(ls); do
   cd $DIR
   rm *.txt
   mv images/* .
   rm -r images
   cd ..
done

# validation data
cd $current/val
annotate_file="val_annotations.txt"
length=$(cat $annotate_file | wc -l)
for i in $(seq 1 $length); do
    # fetch i th line
    line=$(sed -n ${i}p $annotate_file)
    # get file name and directory name
    file=$(echo $line | cut -f1 -d" " )
    directory=$(echo $line | cut -f2 -d" ")
    mkdir -p $directory
    mv images/$file $directory
done
rm -r images
echo "done"

```



è¿è¡Œ`sh tinyimagenet.sh`ï¼Œæ•°æ®è§£å‹å¹¶åˆ†ç±»å‡†å¤‡å¥½ï¼Œè®°472MBã€‚

```
% ls -l
total 5200
drwxrwxr-x    3 hfyan  staff       96 Dec 12  2014 test
drwxrwxr-x  202 hfyan  staff     6464 Dec 12  2014 train
drwxrwxr-x  203 hfyan  staff     6496 Feb 24 11:09 val
-rw-rw-r--    1 hfyan  staff     2000 Feb  9  2015 wnids.txt
-rw-------    1 hfyan  staff  2655750 Feb  9  2015 words.txt
(base) hfyan@HongfeideMac-Studio tiny-imagenet-200 % pwd
/Users/hfyan/data/tiny-imagenet-200

```



### 2. è®­ç»ƒæ¨¡å‹

åŸºäº PyTorch å’Œ torchvision åº“çš„ç¤ºä¾‹ä»£ç ï¼Œè¯¥ä»£ç æ¼”ç¤ºäº†å¦‚ä½•åŠ è½½ ImageNet æ•°æ®é›†ã€æ„å»ºåŸºäºé¢„è®­ç»ƒ ResNet æ¨¡å‹çš„ç¥ç»ç½‘ç»œï¼Œå¹¶è¿›è¡Œå¾®è°ƒè®­ç»ƒå®ç°å›¾åƒåˆ†ç±»ã€‚

ä»£ç `tiny_imagenet_resnet50_epoch25.py`

```python
import os
import copy
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, models, transforms

# è®­ç»ƒå’ŒéªŒè¯å‡½æ•°
def train_model(model, criterion, optimizer, scheduler, dataloaders, dataset_sizes, num_epochs=25, device='cpu'):
    best_model_wts = copy.deepcopy(model.state_dict())
    best_acc = 0.0

    for epoch in range(num_epochs):
        print('Epoch {}/{}'.format(epoch+1, num_epochs))
        print('-' * 10)

        # æ¯ä¸ª epoch åˆ†ä¸ºè®­ç»ƒå’ŒéªŒè¯é˜¶æ®µ
        for phase in ['train', 'val']:
            if phase == 'train':
                model.train()  # è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼
            else:
                model.eval()   # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼

            running_loss = 0.0
            running_corrects = 0

            # éå†æ•°æ®
            for inputs, labels in dataloaders[phase]:
                inputs = inputs.to(device)
                labels = labels.to(device)

                optimizer.zero_grad()  # æ¢¯åº¦æ¸…é›¶

                # å‰å‘ä¼ æ’­
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)

                    # ä»…åœ¨è®­ç»ƒé˜¶æ®µåå‘ä¼ æ’­ä¸å‚æ•°æ›´æ–°
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()

                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)

            if phase == 'train':
                scheduler.step()

            epoch_loss = running_loss / dataset_sizes[phase]

            # MPS åç«¯ä¸æ”¯æŒ float64 è¿ç®—ã€‚è§£å†³æ–¹æ³•æ˜¯ä½¿ç”¨ float32ï¼Œå³è°ƒç”¨ .float()ã€‚
            #epoch_acc = running_corrects.double() / dataset_sizes[phase]
            epoch_acc = running_corrects.float() / dataset_sizes[phase]

            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))

            # ä¿å­˜æœ€ä½³æ¨¡å‹å‚æ•°
            if phase == 'val' and epoch_acc > best_acc:
                best_acc = epoch_acc
                best_model_wts = copy.deepcopy(model.state_dict())
        print()

    print('Best val Acc: {:.4f}'.format(best_acc))
    model.load_state_dict(best_model_wts)
    return model

def main():
    # 1. æ•°æ®é¢„å¤„ç†ä¸åŠ è½½
    # æ³¨æ„ï¼šæ­¤å¤„å‡å®šImageNetæ•°æ®é›†æŒ‰ç…§train/valæ–‡ä»¶å¤¹åˆ†åˆ«å­˜æ”¾å„ç±»åˆ«å›¾ç‰‡ï¼Œ
    # ä¸”æ¯ä¸ªç±»åˆ«ä½œä¸ºä¸€ä¸ªå­æ–‡ä»¶å¤¹å­˜åœ¨
    data_transforms = {
        'train': transforms.Compose([
            transforms.RandomResizedCrop(224),           # éšæœºè£å‰ªä¸º224Ã—224
            transforms.RandomHorizontalFlip(),           # éšæœºæ°´å¹³ç¿»è½¬
            transforms.ToTensor(),                         # è½¬ä¸ºTensor
            transforms.Normalize([0.485, 0.456, 0.406],    # ImageNetå‡å€¼
                                 [0.229, 0.224, 0.225])      # ImageNetæ ‡å‡†å·®
        ]),
        'val': transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),                           # ä¸­å¿ƒè£å‰ª
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406],
                                 [0.229, 0.224, 0.225])
        ]),
    }

    # Tiny ImageNet æ•°æ®è·¯å¾„
    data_dir = '/Users/hfyan/data/tiny-imagenet-200'
    image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),
                                                data_transforms[x])
                      for x in ['train', 'val']}

    # è®¾ç½® num_workers ä¸º 4 ä»¥åˆ©ç”¨å¤šè¿›ç¨‹æ•°æ®åŠ è½½
    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],
                                                    batch_size=128,    # å¯æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
                                                    shuffle=True,
                                                    num_workers=8)
                   for x in ['train', 'val']}

    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}
    class_names = image_datasets['train'].classes

    #device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    # ä½¿ç”¨ MPS ä½œä¸º GPU åç«¯ï¼ˆé€‚ç”¨äº Apple Siliconï¼‰
    if torch.backends.mps.is_available():
        device = torch.device("mps")
        print("Using MPS device for GPU acceleration")
    else:
        device = torch.device("cpu")
        print("MPS device not available, using CPU")

    #2. æ„å»ºæ¨¡å‹ï¼ˆä½¿ç”¨é¢„è®­ç»ƒ ResNet50ï¼‰
    # è¿™é‡Œæˆ‘ä»¬åŠ è½½é¢„è®­ç»ƒçš„ ResNet50 æ¨¡å‹ï¼Œå¹¶ä¿®æ”¹æœ€åçš„å…¨è¿æ¥å±‚ä»¥é€‚åº”Tiny ImageNetçš„ç±»åˆ«æ•°ï¼ˆ200ç±»ï¼‰
    model_ft = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)
    num_ftrs = model_ft.fc.in_features
    model_ft.fc = nn.Linear(num_ftrs, len(class_names))
    model_ft = model_ft.to(device)

    criterion = nn.CrossEntropyLoss()
    optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)

    # å­¦ä¹ ç‡è°ƒæ•´ç­–ç•¥ï¼Œæ¯7ä¸ªepoché™ä½ä¸€æ¬¡å­¦ä¹ ç‡
    exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)

    #3. è®­ç»ƒæ¨¡å‹
    num_epochs = 25  # å¯æ ¹æ®éœ€è¦è°ƒæ•´epochæ•°é‡
    model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,
                           dataloaders, dataset_sizes, num_epochs=num_epochs, device=device)

    #4. ä¿å­˜æ¨¡å‹ï¼Œæ–‡ä»¶åå»ºè®®ä¸º tiny_imagenet_resnet50_epoch25.pth
    torch.save(model_ft.state_dict(), 'tiny_imagenet_resnet50_epoch25.pth')
    print("Model saved as tiny_imagenet_resnet50_epoch25.pth")

if __name__ == '__main__':
    main()

```

> **è¯´æ˜**
>
> - **æ•°æ®é¢„å¤„ç†**
>   ä½¿ç”¨äº† `transforms` å¯¹æ•°æ®è¿›è¡Œäº†æ•°æ®å¢å¼ºï¼ˆå¦‚éšæœºè£å‰ªã€æ°´å¹³ç¿»è½¬ï¼‰ä»¥åŠå½’ä¸€åŒ–ï¼ˆImageNetå¸¸ç”¨çš„å‡å€¼å’Œæ ‡å‡†å·®ï¼‰ã€‚æ•°æ®æ–‡ä»¶å¤¹éœ€è¦ç¬¦åˆ `ImageFolder` çš„è¦æ±‚ï¼Œæ¯ä¸ªç±»åˆ«å­˜æ”¾åœ¨ç‹¬ç«‹çš„å­æ–‡ä»¶å¤¹ä¸­ã€‚
> - **æ¨¡å‹æ„å»º**
>   æœ¬ç¤ºä¾‹ä¸­é‡‡ç”¨é¢„è®­ç»ƒçš„ ResNet50 æ¨¡å‹ï¼Œå¹¶ä¿®æ”¹äº†æœ€åä¸€å±‚å…¨è¿æ¥å±‚ä»¥è¾“å‡ºä¸ç±»åˆ«æ•°åŒ¹é…çš„æ¦‚ç‡åˆ†å¸ƒã€‚
> - **è®­ç»ƒè¿‡ç¨‹**
>   ä»£ç ä¸­å®šä¹‰äº† `train_model` å‡½æ•°ï¼Œå¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒå’ŒéªŒè¯ï¼Œå¹¶åœ¨éªŒè¯é›†ä¸Šé€‰å–å‡†ç¡®ç‡æœ€é«˜çš„æ¨¡å‹å‚æ•°ã€‚å­¦ä¹ ç‡è°ƒåº¦å™¨ç”¨äºé€æ­¥é™ä½å­¦ä¹ ç‡ä»¥ä¾¿æ›´å¥½åœ°æ”¶æ•›ã€‚
> - **æ³¨æ„äº‹é¡¹**
>   - ImageNet æ•°æ®é›†è¾ƒå¤§ï¼Œå»ºè®®åœ¨ä½¿ç”¨æ—¶æ³¨æ„æ•°æ®åŠ è½½ã€å†…å­˜ç®¡ç†å’Œè®­ç»ƒæ—¶é•¿ã€‚
>   - å¦‚éœ€æ›´æ·±å…¥çš„æ¨¡å‹è°ƒä¼˜æˆ–ä½¿ç”¨åˆ†å¸ƒå¼è®­ç»ƒï¼Œè¯·å‚è€ƒ PyTorch å®˜æ–¹æ–‡æ¡£å’Œç›¸å…³èµ„æ–™ã€‚
>
> è¯¥ç¤ºä¾‹ä»£ç ä¸ºå…¥é—¨çº§ç¤ºä¾‹ï¼Œå®é™…é¡¹ç›®ä¸­å¯èƒ½éœ€è¦æ›´å¤šçš„ä¼˜åŒ–å’Œé…ç½®ã€‚
>
> 
>
> **ä¸»å…¥å£ä¿æŠ¤**ï¼šæ‰€æœ‰æ¶‰åŠå¤šè¿›ç¨‹æˆ–å¤šçº¿ç¨‹çš„ä»£ç éƒ½å°è£…åœ¨ `if __name__ == '__main__':` ä¸‹ï¼Œé¿å… macOS ä¸‹çš„å¯åŠ¨é—®é¢˜ã€‚



> **2025/2/24 11:30å¼€å§‹è¿è¡Œï¼Œ16:00ç»“æŸ**
>
> ```
> (base) hfyan@HongfeideMac-Studio data % python tiny_imagenet_resnet50_epoch25.py 
> Using MPS device for GPU acceleration
> Epoch 1/25
> ----------
> train Loss: 5.0366 Acc: 0.0720
> val Loss: 4.1348 Acc: 0.2819
> 
> Epoch 2/25
> ----------
> train Loss: 3.2563 Acc: 0.3406
> val Loss: 1.7006 Acc: 0.6197
> 
> Epoch 3/25
> ----------
> train Loss: 2.1834 Acc: 0.5065
> val Loss: 1.2068 Acc: 0.7062
> 
> Epoch 4/25
> ----------
> train Loss: 1.8635 Acc: 0.5663
> val Loss: 1.0010 Acc: 0.7498
> 
> Epoch 5/25
> ----------
> train Loss: 1.6788 Acc: 0.6029
> val Loss: 0.8927 Acc: 0.7702
> 
> Epoch 6/25
> ----------
> train Loss: 1.5723 Acc: 0.6268
> val Loss: 0.8407 Acc: 0.7808
> 
> Epoch 7/25
> ----------
> train Loss: 1.5044 Acc: 0.6390
> val Loss: 0.7990 Acc: 0.7907
> 
> Epoch 8/25
> ----------
> train Loss: 1.4324 Acc: 0.6567
> val Loss: 0.7788 Acc: 0.7939
> 
> Epoch 9/25
> ----------
> train Loss: 1.4212 Acc: 0.6571
> val Loss: 0.7701 Acc: 0.7981
> 
> Epoch 10/25
> ----------
> train Loss: 1.4054 Acc: 0.6614
> val Loss: 0.7669 Acc: 0.7966
> 
> Epoch 11/25
> ----------
> train Loss: 1.4035 Acc: 0.6615
> val Loss: 0.7634 Acc: 0.7980
> 
> Epoch 12/25
> ----------
> train Loss: 1.3995 Acc: 0.6626
> val Loss: 0.7595 Acc: 0.7990
> 
> Epoch 13/25
> ----------
> train Loss: 1.3882 Acc: 0.6647
> val Loss: 0.7558 Acc: 0.7988
> 
> Epoch 14/25
> ----------
> train Loss: 1.3747 Acc: 0.6680
> val Loss: 0.7517 Acc: 0.7997
> 
> Epoch 15/25
> ----------
> train Loss: 1.3754 Acc: 0.6683
> val Loss: 0.7490 Acc: 0.8006
> 
> Epoch 16/25
> ----------
> train Loss: 1.3685 Acc: 0.6689
> val Loss: 0.7592 Acc: 0.7970
> 
> Epoch 17/25
> ----------
> train Loss: 1.3771 Acc: 0.6681
> val Loss: 0.7567 Acc: 0.8009
> 
> Epoch 18/25
> ----------
> train Loss: 1.3690 Acc: 0.6688
> val Loss: 0.7508 Acc: 0.8011
> 
> Epoch 19/25
> ----------
> train Loss: 1.3716 Acc: 0.6694
> val Loss: 0.7521 Acc: 0.8008
> 
> Epoch 20/25
> ----------
> train Loss: 1.3729 Acc: 0.6687
> val Loss: 0.7527 Acc: 0.8002
> 
> Epoch 21/25
> ----------
> train Loss: 1.3709 Acc: 0.6689
> val Loss: 0.7501 Acc: 0.8014
> 
> Epoch 22/25
> ----------
> train Loss: 1.3706 Acc: 0.6708
> val Loss: 0.7516 Acc: 0.8008
> 
> Epoch 23/25
> ----------
> train Loss: 1.3681 Acc: 0.6696
> val Loss: 0.7502 Acc: 0.8002
> 
> Epoch 24/25
> ----------
> train Loss: 1.3725 Acc: 0.6698
> val Loss: 0.7508 Acc: 0.8003
> 
> Epoch 25/25
> ----------
> train Loss: 1.3708 Acc: 0.6696
> val Loss: 0.7480 Acc: 0.8004
> 
> Best val Acc: 0.8014
> Model saved as tiny_imagenet_resnet50_epoch25.pth
> 
> ```
>
> è·‘äº†4å°æ—¶30åˆ†é’Ÿã€‚
>
> <img src="https://raw.githubusercontent.com/GMyhf/img/main/img/image-20250224171542842.png" alt="image-20250224171542842" style="zoom:50%;" />
>
> 
>
> ```
> % ls -lh *.pth
> -rw-r--r--  1 hfyan  staff    92M Feb 24 16:02 tiny_imagenet_resnet50_epoch25.pth
> ```
>



### 3.åŠ è½½è®­ç»ƒå¥½çš„çš„æ¨¡å‹å¹¶è¿›è¡ŒéªŒè¯

å‰é¢å·²ç»ä¿å­˜äº†æ¨¡å‹æƒé‡ï¼Œå¯ä»¥é€šè¿‡å¦‚ä¸‹æ­¥éª¤åŠ è½½æ¨¡å‹å¹¶åœ¨éªŒè¯é›†ä¸Šè¿›è¡Œè¯„ä¼°ï¼š

1. **åŠ è½½æ¨¡å‹ç»“æ„å’Œæƒé‡**  
   è¯·ç¡®ä¿ä½ å®šä¹‰çš„æ¨¡å‹ç»“æ„ä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ã€‚ä½¿ç”¨ `torch.load` åŠ è½½æƒé‡ï¼Œå¹¶ç”¨ `model.load_state_dict` å¯¼å…¥ã€‚

2. **åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼**  
   è°ƒç”¨ `model.eval()` ç¡®ä¿æ¨¡å‹å…³é—­ BatchNormã€Dropout ç­‰è®­ç»ƒæ—¶ç‰¹æœ‰çš„è¡Œä¸ºã€‚

3. **éå†éªŒè¯æ•°æ®å¹¶è®¡ç®—å‡†ç¡®ç‡**  
   ä½¿ç”¨ `torch.no_grad()` å…³é—­æ¢¯åº¦è®¡ç®—ï¼ŒåŠ å¿«éªŒè¯é€Ÿåº¦ï¼Œå¹¶é˜²æ­¢å†…å­˜æµªè´¹ã€‚

ä¸‹é¢æ˜¯ä¸€ä¸ªå®Œæ•´çš„ç¤ºä¾‹ä»£ç ï¼Œ`eval_tiny_imagenet_resnet50_epoch25_pth.py `ï¼š

```python
import os
import torch
import torch.nn as nn
from torchvision import datasets, models, transforms

# æ•°æ®é¢„å¤„ç†
data_transforms = {
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225])
    ]),
}

# ç¡®ä¿å­è¿›ç¨‹å®‰å…¨å¯åŠ¨
if __name__ == '__main__':
    data_dir = '/Users/hfyan/data/tiny-imagenet-200'
    val_dir = os.path.join(data_dir, 'val')
    val_dataset = datasets.ImageFolder(val_dir, data_transforms['val'])
    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64,
                                             shuffle=False, num_workers=4)

    # é€‰æ‹©è®¾å¤‡
    if torch.backends.mps.is_available():
        device = torch.device("mps")
        print("Using MPS device for GPU acceleration")
    else:
        device = torch.device("cpu")
        print("MPS device not available, using CPU")

    # åŠ è½½æ¨¡å‹
    model_ft = models.resnet50(pretrained=False)
    num_ftrs = model_ft.fc.in_features
    model_ft.fc = nn.Linear(num_ftrs, len(val_dataset.classes))
    model_ft = model_ft.to(device)

    # åŠ è½½æ¨¡å‹æƒé‡
    model_path = 'tiny_imagenet_resnet50_epoch25.pth'
    model_ft.load_state_dict(torch.load(model_path, map_location=device))

    # è¯„ä¼°æ¨¡å¼
    model_ft.eval()

    # æ¨¡å‹è¯„ä¼°
    running_corrects = 0
    total_samples = 0

    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs = inputs.to(device)
            labels = labels.to(device)

            outputs = model_ft(inputs)
            _, preds = torch.max(outputs, 1)
            running_corrects += torch.sum(preds == labels.data)
            total_samples += inputs.size(0)

    val_acc = running_corrects.float() / total_samples
    print('Validation Accuracy: {:.4f}'.format(val_acc))

```

> **éªŒè¯æ­¥éª¤**ï¼š  
>
> - åŠ è½½ä¸ä½ è®­ç»ƒæ—¶ä¸€è‡´çš„æ¨¡å‹ç»“æ„ã€‚  
> - ä½¿ç”¨ `model.load_state_dict()` åŠ è½½æƒé‡ã€‚  
> - è°ƒç”¨ `model.eval()` è¿›å…¥éªŒè¯æ¨¡å¼ã€‚  
> - éå†éªŒè¯æ•°æ®é›†ï¼Œè®¡ç®—å‡†ç¡®ç‡æˆ–å…¶ä»–æŒ‡æ ‡ã€‚
>
> è¿™æ ·ï¼Œä½ å°±å¯ä»¥åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹å¹¶å¯¹éªŒè¯é›†æ•°æ®è¿›è¡Œæµ‹è¯•ã€‚
>
> ![image-20250224171857564](https://raw.githubusercontent.com/GMyhf/img/main/img/image-20250224171857564.png)
>
> 
>
> ```python
> (base) hfyan@HongfeideMac-Studio data % python eval_tiny_imagenet_resnet50_epoch25_pth.py 
> Using MPS device for GPU acceleration
> /Users/hfyan/miniconda3/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
>   warnings.warn(
> /Users/hfyan/miniconda3/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.
>   warnings.warn(msg)
> Validation Accuracy: 0.8014
> (base) hfyan@HongfeideMac-Studio data % 
> ```
>





# å‚è€ƒæ–‡çŒ®

[1] Dartmouth workshop - Wikipedia

https://en.wikipedia.org/wiki/Dartmouth_workshop

[2]OpenAI Presents GPT-3, a 175 Billion Parameters Language Model | NVIDIA Technical Blog. July 07, 2020.

https://developer.nvidia.com/blog/openai-presents-gpt-3-a-175-billion-parameters-language-model/

[3] GPT-4 Technical Report. March 27, 2023.

https://cdn.openai.com/papers/gpt-4.pdf

[4] Transformer (deep learning architecture) - Wikipedia

https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)

[5] GPT-4 | OpenAI. March 14, 2023.

https://openai.com/index/gpt-4-research/